<!DOCTYPE html><html class="appearance-auto" lang="zh-CN"><head><meta charset="UTF-8"><title>一次线上内存使用率异常问题排查</title><meta name="description" content="行万里路，读万卷书"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><script>var _hmt = _hmt || [];
(function() {
var hm = document.createElement("script");
hm.src = "https://hm.baidu.com/hm.js?" + '2c076421eb9f21a0a143f8ee9c4ab171';
var s = document.getElementsByTagName("script")[0];
s.parentNode.insertBefore(hm, s);
})();</script><!-- End Baidu Analytics --><meta name="referrer" content="no-referrer"><link rel="icon" href="/null"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/post.css"><link rel="stylesheet" href="/style/themes/highlight-theme-light.css"><script src="/js/highlight.pack.js"></script><meta name="description" content="一、背景朋友的一个服务，某个集群内存的RSS使用率一直在80%左右，他用的是8核16G, 双机房一共206个实例。

但是在pprof里面查的堆内存才使用了6.3G左右，程序里面主要用了6G的LocalCache所以heap用了6.3G是符合预期的。

朋友让我帮忙看下，额外的内存到底是被啥占用了。
二、基础知识2.1 TCMalloc 算法Thread-Caching Malloc 是Google开发的内存分配算法库，最开始它是作为Google的一个性能工具库perftools的一部分。
TCMalloc是用来替代传统的malloc内存分配函数。它有减少内存碎片，适用于多核，更好的并行性支持等特性。
2.2 mmap 函数mmap它的主要功能是将一个虚拟内存区域与一个磁盘上的文件关联起来，以初始化这个虚拟.."><meta name="generator" content="Hexo 5.4.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">Ryo's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><div class="is-full-height" id="postTopic"><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">一次线上内存使用率异常问题排查</p><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">点击返回顶部</p></div></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">首页</a></h3><h3 class="is-inline-block"><a href="/about">关于</a></h3><h3 class="is-inline-block"><a href="/archives">归档</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">首页</a></h3><h3 class="is-inline-block"><a href="/about">关于</a></h3><h3 class="is-inline-block"><a href="/archives">归档</a></h3></header><main><main class="container is-max-widescreen content section post-page pt-4 px-4"><div class="columns is-flex-desktop is-justify-content-center is-flex-direction-row-reverse"><div class="column is-3 is-hidden-mobile"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E8%83%8C%E6%99%AF"><span class="toc-text">一、背景</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86"><span class="toc-text">二、基础知识</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-TCMalloc-%E7%AE%97%E6%B3%95"><span class="toc-text">2.1 TCMalloc 算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-mmap-%E5%87%BD%E6%95%B0"><span class="toc-text">2.2 mmap 函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-3-Golang-%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D"><span class="toc-text">2.3 Golang 内存分配</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-4-TCMalloc-%E7%9A%84%E5%86%85%E5%AD%98%E6%B5%AA%E8%B4%B9"><span class="toc-text">2.4 TCMalloc 的内存浪费</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-5-Go-%E6%9F%A5%E7%9C%8B%E5%86%85%E5%AD%98%E4%BD%BF%E7%94%A8%E6%83%85%E5%86%B5%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F"><span class="toc-text">2.5 Go 查看内存使用情况几种方式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-6-Sysmon-%E7%9B%91%E6%8E%A7%E7%BA%BF%E7%A8%8B"><span class="toc-text">2.6 Sysmon 监控线程</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%E8%BF%87%E7%A8%8B"><span class="toc-text">三、问题排查过程</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2%EF%BC%9F"><span class="toc-text">3.1 内存泄露？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2-madvise"><span class="toc-text">3.2 madvise</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF-madvise-%EF%BC%9F"><span class="toc-text">什么是 madvise ？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Go-Runtime-%E5%AF%B9-madvise-%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-text">Go Runtime 对 madvise 的使用</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-3-memory-scavenging"><span class="toc-text">2.3 memory scavenging</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#GC-%E8%A7%A6%E5%8F%91%E6%9C%BA%E5%88%B6"><span class="toc-text">GC 触发机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#scavenging-%E8%A7%A6%E5%8F%91%E6%9C%BA%E5%88%B6"><span class="toc-text">scavenging 触发机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA"><span class="toc-text">结论</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-text">总结</span></a></li></ol></div><div class="column is-9"><header class="my-4"><a href="/tags/Golang"><i class="tag post-item-tag">Golang</i></a></header><h1 class="mt-0 mb-1 is-family-serif" id="postTitle">一次线上内存使用率异常问题排查</h1><time class="has-text-grey" datetime="2022-06-02T01:00:00.000Z">2022-06-02</time><article class="mt-2 post-content"><h1 id="一、背景"><a href="#一、背景" class="headerlink" title="一、背景"></a>一、背景</h1><p>朋友的一个服务，某个集群内存的<code>RSS</code>使用率一直在<code>80%</code>左右，他用的是<code>8核16G</code>, 双机房一共<code>206</code>个实例。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/12321605-5001071b9627f07b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>但是在<code>pprof</code>里面查的堆内存才使用了<code>6.3G</code>左右，程序里面主要用了<code>6G</code>的<code>LocalCache</code>所以<code>heap</code>用了<code>6.3G</code>是符合预期的。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/12321605-9602a9ef42c1af94.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>朋友让我帮忙看下，额外的内存到底是被啥占用了。</p>
<h1 id="二、基础知识"><a href="#二、基础知识" class="headerlink" title="二、基础知识"></a>二、基础知识</h1><h2 id="2-1-TCMalloc-算法"><a href="#2-1-TCMalloc-算法" class="headerlink" title="2.1 TCMalloc 算法"></a>2.1 TCMalloc 算法</h2><p><a target="_blank" rel="noopener" href="http://goog-perftools.sourceforge.net/doc/tcmalloc.html">Thread-Caching Malloc</a> 是<code>Google</code>开发的内存分配算法库，最开始它是作为<code>Google</code>的一个性能工具库<code>perftools</code>的一部分。</p>
<p><code>TCMalloc</code>是用来替代传统的<code>malloc</code>内存分配函数。它有减少内存碎片，适用于多核，更好的并行性支持等特性。</p>
<h2 id="2-2-mmap-函数"><a href="#2-2-mmap-函数" class="headerlink" title="2.2 mmap 函数"></a>2.2 mmap 函数</h2><p><code>mmap</code>它的主要功能是将一个<code>虚拟内存区域</code>与一个<code>磁盘上的文件</code>关联起来，以初始化这个虚拟内存区域的内容，这个过程成为内存映射（<code>memory mapping</code>）。</p>
<p>直白一点说，就是可以将<code>一个文件</code>，映射到一段<code>虚拟内存</code>，写内存的时候操作系统会自动同步内存的内容到文件。内存同步到磁盘，还涉及到一个<code>PageCache</code>的概念，这里不去过度发散，感兴趣朋友可以自己搜下。</p>
<p><code>文件</code>可以是磁盘上的一个<code>实体文件</code>，比如<code>kafka</code>写日志文件的时候，就用了<code>mmap</code>。</p>
<p><code>文件</code>也可以是一个<code>匿名文件</code>，这种场景<code>mmap</code>不会去写磁盘，主要用于内存申请的场景。比如调用<code>malloc</code>函数申请内存，当申请的大小超过<code>MMAP_THRESHOLD</code>（默认是<code>128K</code>）大小，内核就会用<code>mmap</code>去申请内存。再比如<code>TCMalloc</code>也是通过<code>mmap</code>来申请一大块内存（<code>匿名文件</code>），然后切割内存，分配给程序使用。</p>
<p>网上很多资料一介绍<code>mmap</code>，就会说到<code>zero copy</code>，就是相对于<code>标准IO</code>来说少了一次内存<code>Copy</code>的开销。让大多数人忽略了<code>mmap</code>本质的功能，认为<code>mmap=zero copy</code></p>
<p><img src="https://upload-images.jianshu.io/upload_images/12321605-58f26fcf756d90b2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>还有一个值得一说的<code>mmap</code>申请的内存不在虚拟地址空间的<code>堆区</code>，在<code>内存映射段（Memory Mapping Region）</code></p>
<p><img src="https://upload-images.jianshu.io/upload_images/12321605-1987f229490dbaf5.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Application.jpg"></p>
<h2 id="2-3-Golang-内存分配"><a href="#2-3-Golang-内存分配" class="headerlink" title="2.3 Golang 内存分配"></a>2.3 Golang 内存分配</h2><p><a target="_blank" rel="noopener" href="https://github.com/golang/go/blob/master/src/runtime/malloc.go">Golang的内存分配</a> 是用的 <code>TCMalloc</code>（<code>Thread-Caching Malloc</code>）算法, 简单点说就是<code>Golang</code>是使用 <a target="_blank" rel="noopener" href="https://github.com/golang/go/blob/master/src/runtime/mem_linux.go#L185">mmap</a> 函数去操作系统申请一大块内存，然后把内存按照 <code>0~32KB``68</code>个 <code>size</code> 类型的<code>mspan</code>，每个<code>mspan</code>按照它自身的属性 <a target="_blank" rel="noopener" href="https://github.com/golang/go/blob/master/src/runtime/sizeclasses.go#L93">Size Class</a> 的大小分割成若干个<code>object</code><a target="_blank" rel="noopener" href="https://github.com/golang/go/blob/go1.16.6/src/runtime/sizeclasses.go">（每个span默认是8K）</a>，因为分需要<code>gc</code>的<code>mspan</code>和不需要<code>gc</code>的<code>mspan</code>，所以一共有<code>136</code>种类型。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/12321605-17d63fba4dcbecc5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p><code>mspan</code>：<code>Go</code>中内存管理的基本单元，是由一片连续的<code>8KB</code>的页组成的大块内存，每个<code>mspan</code>按照它自身的属性<code>Size Class</code>的大小分割成若干个<code>object</code>，<code>mspan</code>的<code>Size Class</code>共有<a target="_blank" rel="noopener" href="https://github.com/golang/go/blob/master/src/runtime/sizeclasses.go#L89">68种（算上0）</a> , <a target="_blank" rel="noopener" href="https://github.com/golang/go/blob/master/src/runtime/mheap.go#L528"> numSpanClasses = _NumSizeClasses &lt;&lt; 1</a> (因为需要区分需要GC和不需要GC的)</p>
<p><code>mcache</code>：每个工作线程都会绑定一个<code>mcache</code>，本地缓存可用的<code>mspan</code>资源。</p>
<p><code>mcentral</code>：为所有 <code>mcache</code>提供切分好的 <code>mspan</code>资源。需要加锁</p>
<p><code>mheap</code>：代表<code>Go</code>程序持有的所有堆空间，<code>Go</code>程序使用一个<code>mheap</code>的全局对象<a target="_blank" rel="noopener" href="https://github.com/golang/go/blob/master/src/runtime/mheap.go#L216">_mheap</a>来管理堆内存。</p>
<!--![image.png](https://upload-images.jianshu.io/upload_images/12321605-97e487c33ee90c7c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
-->

<p><code>Go</code>的内存分配器在分配对象时，根据对象的大小，分成三类：小对象（小于等于<code>16B</code>）、一般对象（大于<code>16B</code>，小于等于<code>32KB</code>）、大对象（大于<code>32KB</code>）。</p>
<p>大体上的分配流程：</p>
<ul>
<li><code>&gt;32KB</code> 的对象，直接从<code>mheap</code>上分配；</li>
<li><code>(16B,32KB]</code> 的对象，首先计算对象的规格大小，然后使用<code>mcache</code>中相应规格大小的<code>mspan</code>分配；</li>
<li><code>&lt;=16B</code> 的对象使用<code>mcache</code>的<code>tiny</code>分配器分配；</li>
</ul>
<p>如果<code>mcache</code>没有相应规格大小的<code>mspan</code>，则向<code>mcentral</code>申请<br>如果<code>mcentral</code>没有相应规格大小的<code>mspan</code>，则向<code>mheap</code>申请<br>如果<code>mheap</code>中也没有合适大小的<code>mspan</code>，则向操作系统申请</p>
<h2 id="2-4-TCMalloc-的内存浪费"><a href="#2-4-TCMalloc-的内存浪费" class="headerlink" title="2.4 TCMalloc 的内存浪费"></a>2.4 TCMalloc 的内存浪费</h2><p><code>Golang</code>的 <a target="_blank" rel="noopener" href="https://github.com/golang/go/blob/master/src/runtime/sizeclasses.go#L6">sizeclasses.go</a> 源码里面已经给我们已经计算了出每个<code>size</code>的<code>tail waste</code>和<code>max waste</code>比例</p>
<pre><code>// class  bytes/obj  bytes/span  objects  tail waste  max waste  min align
//     1          8        8192     1024           0     87.50%          8
//     2         16        8192      512           0     43.75%         16
//     3         24        8192      341           8     29.24%          8
//     4         32        8192      256           0     21.88%         32
//     5         48        8192      170          32     31.52%         16
//     6         64        8192      128           0     23.44%         64
//     7         80        8192      102          32     19.07%         16
//     8         96        8192       85          32     15.95%         32
//     9        112        8192       73          16     13.56%         16
//    10        128        8192       64           0     11.72%        128
.... 略
//    58      14336       57344        4           0      5.35%       2048
//    59      16384       16384        1           0     12.49%       8192
//    60      18432       73728        4           0     11.11%       2048
//    61      19072       57344        3         128      3.57%        128
//    62      20480       40960        2           0      6.87%       4096
//    63      21760       65536        3         256      6.25%        256
//    64      24576       24576        1           0     11.45%       8192
//    65      27264       81920        3         128     10.00%        128
//    66      28672       57344        2           0      4.91%       4096
//    67      32768       32768        1           0     12.50%       8192
</code></pre>
<p>我们看下<code>tail waste</code>和<code>max waste</code>的计算方式，<a target="_blank" rel="noopener" href="https://github.com/golang/go/blob/master/src/runtime/mksizeclasses.go#L238">源码如下</a>：</p>
<pre><code>    spanSize := c.npages * pageSize
    objects := spanSize / c.size
    tailWaste := spanSize - c.size*(spanSize/c.size)
    maxWaste := float64((c.size-prevSize-1)*objects+tailWaste) / float64(spanSize)
    alignBits := bits.TrailingZeros(uint(c.size))
    if alignBits &gt; pageShift {
        // object alignment is capped at page alignment
        alignBits = pageShift
    }
    for i := range minAligns {
        if i &gt; alignBits {
            minAligns[i] = 0
        } else if minAligns[i] == 0 {
            minAligns[i] = c.size
        }
    }
</code></pre>
<p><img src="https://upload-images.jianshu.io/upload_images/12321605-44574dcf46fe8b7c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p><code>sizeclase=8</code>的时候<code>obj= 96</code>，所以<code>tailWaste = 8192%96 = 32</code>，<code>maxWaste = ((96-80-1)* 85 + 32)/ 8192 = 0.1595</code></p>
<h2 id="2-5-Go-查看内存使用情况几种方式"><a href="#2-5-Go-查看内存使用情况几种方式" class="headerlink" title="2.5 Go 查看内存使用情况几种方式"></a>2.5 Go 查看内存使用情况几种方式</h2><ol>
<li><p>执行前添加系统环境变量<code>GODEBUG='gctrace=1'</code>来跟踪打印垃圾回收器信息，具体打印的内容含义可以参考<a target="_blank" rel="noopener" href="https://pkg.go.dev/runtime">官方文档</a>。</p>
<pre><code> gctrace: 设置gctrace=1会使得垃圾回收器在每次回收时汇总所回收内存的大小以及耗时，
 并将这些内容汇总成单行内容打印到标准错误输出中。
 这个单行内容的格式以后可能会发生变化。
 目前它的格式：
     gc # @#s #%: #+#+# ms clock, #+#/#/#+# ms cpu, #-&gt;#-&gt;# MB, # MB goal, # P
 各字段的含义：
     gc #        GC次数的编号，每次GC时递增
     @#s         距离程序开始执行时的时间
     #%          GC占用的执行时间百分比
     #+...+#     GC使用的时间
     #-&gt;#-&gt;# MB  GC开始，结束，以及当前活跃堆内存的大小，单位M
     # MB goal   全局堆内存大小
     # P         使用processor的数量
 如果信息以"(forced)"结尾，那么这次GC是被runtime.GC()调用所触发。
 
 如果gctrace设置了任何大于0的值，还会在垃圾回收器将内存归还给系统时打印一条汇总信息。
 这个将内存归还给系统的操作叫做scavenging。
 这个汇总信息的格式以后可能会发生变化。
 目前它的格式：
     scvg#: # MB released  printed only if non-zero
     scvg#: inuse: # idle: # sys: # released: # consumed: # (MB)
 各字段的含义:
     scvg#        scavenge次数的变化，每次scavenge时递增
     inuse: #     MB 垃圾回收器中使用的大小
     idle: #      MB 垃圾回收器中空闲等待归还的大小
     sys: #       MB 垃圾回收器中系统映射内存的大小
     released: #  MB 归还给系统的大小
     consumed: #  MB 从系统申请的大小
</code></pre>
</li>
<li><p>代码中使用<code>runtime.ReadMemStats</code>来获取程序当前内存的使用情况</p>
<pre><code> var m runtime.MemStats
 runtime.ReadMemStats(&amp;m)
</code></pre>
</li>
<li><p>通过<code>pprof</code>获取</p>
<pre><code>  http://127.0.0.1:10000/debug/pprof/heap?debug=1
  
  在输出的最下面有MemStats的信息
  
  # runtime.MemStats
 # Alloc = 105465520
 # TotalAlloc = 334874848
 # Sys = 351958088
 # Lookups = 0
 # Mallocs = 199954
 # Frees = 197005
 # HeapAlloc = 105465520
 # HeapSys = 334954496
 # HeapIdle = 228737024
 # HeapInuse = 106217472
 # HeapReleased = 218243072
 # HeapObjects = 2949
 # Stack = 589824 / 589824
 # MSpan = 111656 / 212992
 # MCache = 9600 / 16384
 # BuckHashSys = 1447688
 # GCSys = 13504096
 # OtherSys = 1232608
 # NextGC = 210258400
 # LastGC = 1653972448553983197
</code></pre>
</li>
</ol>
<h2 id="2-6-Sysmon-监控线程"><a href="#2-6-Sysmon-监控线程" class="headerlink" title="2.6 Sysmon 监控线程"></a>2.6 Sysmon 监控线程</h2><p><code>Go Runtime</code>在启动程序的时候，会创建一个独立的<code>M</code>作为监控线程，称为<code>sysmon</code>，它是一个系统级的<code>daemon</code>线程。这个<code>sysmon</code>独立于<code>GPM</code>之外，也就是说不需要<code>P</code>就可以运行，因此官方工具<code>go tool trace</code>是无法追踪分析到此线程。</p>
<p><code>sysmon</code>执行一个无限循环，一开始每次循环休眠<code>20us</code>，之后（<code>1ms</code>后）每次休眠时间倍增，最终每一轮都会休眠 <code>10ms</code>。</p>
<p><code>sysmon</code>主要如下几件事</p>
<ul>
<li>释放闲置超过<code>5</code>分钟的<code>span</code>物理内存，<code>scavenging</code>。（Go 1.12之前）</li>
<li>如果超过两分钟没有执行垃圾回收，则强制执行<code>GC</code>。</li>
<li>将长时间未处理的<code>netpoll</code>结果添加到任务队列</li>
<li>向长时间运行的<code>g</code>进行抢占</li>
<li>收回因为<code>syscall</code>而长时间阻塞的<code>p</code></li>
</ul>
<h1 id="三、问题排查过程"><a href="#三、问题排查过程" class="headerlink" title="三、问题排查过程"></a>三、问题排查过程</h1><h2 id="3-1-内存泄露？"><a href="#3-1-内存泄露？" class="headerlink" title="3.1 内存泄露？"></a>3.1 内存泄露？</h2><p>服务内存不正常，本能反应是不是内存泄露了？朋友说他们服务内存一周内一直都是在<code>80%~85%</code>左右波动，然后<code>pprof</code>看的<code>heap</code>的使用也是符合预期的。看了下程序的<code>Runtime</code>监控，容器的内存监控，都是正常的。基本可以排除内存泄露的可能性。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/12321605-4b7d1d580f80422e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/12321605-bdf636713d6259f8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h2 id="3-2-madvise"><a href="#3-2-madvise" class="headerlink" title="3.2 madvise"></a>3.2 madvise</h2><p>排除了内存泄露的可能性，再一个让人容易想到的坑就是<code>madvise</code>，这个感觉是<code>GO 1.12</code> ~ <code>Go 1.15</code> 版本，被提到很多次的问题。</p>
<h3 id="什么是-madvise-？"><a href="#什么是-madvise-？" class="headerlink" title="什么是 madvise ？"></a>什么是 madvise ？</h3><p><a target="_blank" rel="noopener" href="https://man7.org/linux/man-pages/man2/madvise.2.html">madvise()</a> 函数建议内核,在从<code>addr</code>指定的地址开始,长度等于<code>len</code>参数值的范围内,该区域的用户虚拟内存应遵循特定的使用模式。内核使用这些信息优化与指定范围关联的资源的处理和维护过程。如果使用<a target="_blank" rel="noopener" href="https://man7.org/linux/man-pages/man2/madvise.2.html">madvise()</a>函数的程序明确了解其内存访问模式,<strong>则使用此函数可以提高系统性能</strong>。”</p>
<ul>
<li><code>MADV_FREE</code> ：（<code>Linux 4.5</code>以后开始支持这个特性），内核在当出现内存压力时才会主动释放这块内存。</li>
<li><code>MADV_DONTNEED</code>：预计未来长时间不会被访问，可以认为应用程序完成了对这部分内容的访问，因此内核可以立即释放与之相关的资源。</li>
</ul>
<h3 id="Go-Runtime-对-madvise-的使用"><a href="#Go-Runtime-对-madvise-的使用" class="headerlink" title="Go Runtime 对 madvise 的使用"></a>Go Runtime 对 madvise 的使用</h3><p>在<code>Go 1.12</code>版本的时候，为了提高内存的使用效率，把<code>madvise</code>的参数从<code>MADV_DONTNEED</code>改成<code>MADV_FREE</code>，<a target="_blank" rel="noopener" href="https://go-review.googlesource.com/c/go/+/135395/">具体可以看这个CR</a>，然后又加个<code>debug</code>参数来可以控制分配规则改回为<code>MADV_DONTNEED</code>，<a target="_blank" rel="noopener" href="https://go-review.googlesource.com/c/go/+/155931/">具体可以看这个CR</a></p>
<p><code>runtime</code>中调用<code>madvise</code>的<a target="_blank" rel="noopener" href="https://github.com/golang/go/blob/master/src/runtime/mem_linux.go#L106">代码如下</a>： </p>
<pre><code>var adviseUnused = uint32(_MADV_FREE)

func sysUnused(v unsafe.Pointer, n uintptr) {
    // ... 略
    
    var advise uint32
    if debug.madvdontneed != 0 {
        advise = _MADV_DONTNEED
    } else {
        advise = atomic.Load(&amp;adviseUnused)
    }
    if errno := madvise(v, n, int32(advise)); advise == _MADV_FREE &amp;&amp; errno != 0 {
        // MADV_FREE was added in Linux 4.5. Fall back to MADV_DONTNEED if it is
        // not supported.
        atomic.Store(&amp;adviseUnused, _MADV_DONTNEED)
        madvise(v, n, _MADV_DONTNEED)
    }
}
</code></pre>
<p>使用<code>MADV_FREE</code>的问题是，<code>Golang</code>程序释放的内存，操作系统并不会立即回收，只有操作系统内存紧张的时候，才会主动去回收，而我们的程序，都是跑在容器中的，所以造成了，我们容器内存使用快满了，但是物理机的内存还有很多内存，导致的现象就是用<code>pprof</code>看的内存不一样跟看的<code>RES</code>相差巨大。</p>
<p>由于<code>MADV_FREE</code>导致的<code>pprof</code>和<code>top</code>内存监控不一致的问题，导致很多开发者在<code>GO</code>的<code>GitHub</code>上提<code>issue</code>，最后<code>Austin Clements</code>（<code>Go</code>开源大佬）拍板，把<code>MADV_FREE</code>改回了<code>MADV_DONTNEED</code>，<a target="_blank" rel="noopener" href="https://go-review.googlesource.com/c/go/+/267100">具体可以看这个CR</a></p>
<p>大佬也在代码里面做了个简单解释如下：</p>
<pre><code>// On Linux, MADV_FREE is faster than MADV_DONTNEED,
// but doesn't affect many of the statistics that
// MADV_DONTNEED does until the memory is actually
// reclaimed. This generally leads to poor user
// experience, like confusing stats in top and other
// monitoring tools; and bad integration with
// management systems that respond to memory usage.
// Hence, default to MADV_DONTNEED.
</code></pre>
<p>该改动已经在 <a target="_blank" rel="noopener" href="https://go.dev/doc/go1.16">Go 1.16</a> 合入了。我看了下朋友服务的<code>GO</code>版本是<code>1.17</code>，所以是<code>MADV_FREE</code>的问题基本也可以排除了。</p>
<h2 id="2-3-memory-scavenging"><a href="#2-3-memory-scavenging" class="headerlink" title="2.3 memory scavenging"></a>2.3 memory scavenging</h2><p>既然排除了<code>内存泄露</code>，然后也不是<code>madvise()</code>的问题，只能猜想是不是<strong>内存是不是还没有归还给操作系统</strong>。</p>
<p><code>Go</code>把内存归还给系统的操作叫做<code>scavenging</code>。在<code>Go</code>程序执行过程中，当对象释放的时候，对象占用的内存并没有立即返还给操作系统(为了提高内存分配效率，方式归还以后又理解需要申请)，而是需要等待<code>GC</code>（定时或者条件触发）和<code>scavenging</code>（定时或者条件触发）才会把空闲的内存归还给操作系统。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/12321605-bb7f35b62139fda7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>当然我们也可以在代码里面调用<code>debug.FreeOSMemory()</code>来主动释放内存。<code>debug.FreeOSMemory()</code>的功能是强制进行垃圾收集，然后尝试将尽可能多的内存返回给操作系统。<a target="_blank" rel="noopener" href="https://github.com/golang/go/blob/master/src/runtime/mheap.go#L1573">具体代码实现如下</a>：</p>
<pre><code>//go:linkname runtime_debug_freeOSMemory runtime/debug.freeOSMemory
func runtime_debug_freeOSMemory() {
    GC() // 第一步强制 GC
    systemstack(func() { mheap_.scavengeAll() }) // 第二步 scavenging
}
</code></pre>
<h3 id="GC-触发机制"><a href="#GC-触发机制" class="headerlink" title="GC 触发机制"></a>GC 触发机制</h3><p><code>GO</code>的<code>GC</code>触发可以分为主动触发和被动触发，主动触发就是在代码里面主动执行<code>runtime.GC()</code>，线上环境我们一般很少主动触发。这里我们主要讲下被动触发，被动触发有两种情况：</p>
<ol>
<li><p>当前内存分配达到一定比例则触发，可以通过环境变量<code>GOGC</code>或者代码中调用<code>runtime.SetGCPercent</code>来设置，默认是<code>100</code>，表示内存增长<code>1</code>倍触发一次<code>GC</code>。比如一次回收完毕后，内存的使用量为<code>5M</code>，那么下次回收的时机则是内存分配达到<code>10M</code>的时候。</p>
</li>
<li><p>定时触发<code>GC</code>，这个是<code>sysmon</code>线程里面干的时区，一般是<code>2</code>分钟（<code>runtime</code>中写死的）内没有触发<code>GC</code>，会强制执行一次<code>GC</code>。<a target="_blank" rel="noopener" href="https://github.com/golang/go/blob/master/src/runtime/proc.go#L5250">具体代码如下</a>：</p>
<pre><code> // forcegcperiod is the maximum time in nanoseconds between garbage
 // collections. If we go this long without a garbage collection, one
 // is forced to run.
 //
 // This is a variable for testing purposes. It normally doesn't change.
 var forcegcperiod int64 = 2 * 60 * 1e9
</code></pre>
</li>
</ol>
<pre><code>    // gcTriggerTime indicates that a cycle should be started when
    // it's been more than forcegcperiod nanoseconds since the
    // previous GC cycle.
    gcTriggerTime

    // check if we need to force a GC
    if t := (gcTrigger{kind: gcTriggerTime, now: now}); t.test() &amp;&amp; atomic.Load(&amp;forcegc.idle) != 0 {
        lock(&amp;forcegc.lock)
        forcegc.idle = 0
        var list gList
        list.push(forcegc.g)
        injectglist(&amp;list)
        unlock(&amp;forcegc.lock)
    }
</code></pre>
<h3 id="scavenging-触发机制"><a href="#scavenging-触发机制" class="headerlink" title="scavenging 触发机制"></a>scavenging 触发机制</h3><p><code>GO 1.12</code>之前是通过定时触发，<code>2.5min</code>会执行一次<code>scavenge</code>，然后会回收<code>超过5分钟内没有使用过的mspan</code>，<a target="_blank" rel="noopener" href="https://github.com/golang/go/blob/release-branch.go1.12/src/runtime/proc.go#L4357">具体源码如下</a>：</p>
<pre><code>// If a heap span goes unused for 5 minutes after a garbage collection,
// we hand it back to the operating system.
scavengelimit := int64(5 * 60 * 1e9)

// scavenge heap once in a while
if lastscavenge+scavengelimit/2 &lt; now {
    mheap_.scavenge(int32(nscavenge), uint64(now), uint64(scavengelimit))
    lastscavenge = now
    nscavenge++
}
</code></pre>
<p>这样会有个问题是，如果不停的有大量内存申请和释放，会导致<code>mspan</code>内存一直不会释放给<code>操作系统</code>（因为不停被使用然后释放），导致堆内存监控和<code>RSS</code>监控不一致。具体可以看 <a target="_blank" rel="noopener" href="https://github.com/golang/go/issues/14045">runtime: reclaim memory used by huge array that is no longer referenced</a> 这个<code>Issue</code>，还有一个问题因为内存释放不及时，容易在低内存的设备上<code>OOM</code>，具体可以看 <a target="_blank" rel="noopener" href="https://medium.com/samsara-engineering/running-go-on-low-memory-devices-536e1ca2fe8f">Running Go on Low Memory Devices
</a> 这个文章。</p>
<p>基于以上这些问题，<code>Austin Clements</code>大佬提交了一个<code>Issue</code>：<a target="_blank" rel="noopener" href="https://github.com/golang/go/issues/16930">runtime: make the scavenger more prompt</a>，<code>Austin Clements</code>提出如果我们只考虑在<code>scavenge</code>阶段需要释放多少个<code>mspan</code>，这个是比较难的。我们应该分离关注点，通过关注<code>释放和重新获得内存的成本</code>，<code>下次GC的堆大小</code>，<code>我们愿意承担的CPU和内存开销</code>来计算出应该释放多少<code>mspan</code>，提议保留的内存大小应该是过去一段时间内，堆内存回收大小的峰值乘以一个常数，计算回收方式如下：</p>
<pre><code>retain = C * max(current heap goal, max({heap goals of GCs over the past T seconds}))
C = 1 + ε = 1.1
T = 10 seconds
</code></pre>
<p>这个提议<code>2016.08.31</code>提出以后，但是一直没有人去实现。</p>
<p>直到<code>2019.02.21</code>的时候<code>Michael Knyszek</code>重新提了一个<code>Proposal</code>：<a target="_blank" rel="noopener" href="https://github.com/golang/go/issues/30333">runtime: smarter scavenging</a>。</p>
<p>这个<code>Proposal</code>目标是：</p>
<ol>
<li>降低<code>Go</code>应用程序的<code>RSS</code>平均值和峰值。</li>
<li>使用尽可能少<code>CPU</code>来持续降低<code>RSS</code>。</li>
</ol>
<p><code>runtime</code>做内存回收策略，有三个关键问题</p>
<ol>
<li>内存回收的速率是多少？</li>
<li>我们应该保留多少内存？</li>
<li>什么内存我们应该归还给操作系统？</li>
</ol>
<p>实现方法</p>
<ol>
<li><code>Scavenge</code>速度应该与程序<code>Alloc</code>内存的速度保持一致。</li>
<li>保留的内存大小应该是一个常量乘以过去<code>N</code>次<code>GC</code>的峰值。<a target="_blank" rel="noopener" href="https://github.com/golang/go/issues/16930">runtime: make the scavenger more prompt</a></li>
<li>在<code>unscavenged spans</code>中，优先清除基地址高的。</li>
</ol>
<p>上面的<code>Proposal</code>主要提交如下：</p>
<p><a target="_blank" rel="noopener" href="https://go-review.googlesource.com/c/go/+/142960/">runtime: add background scavenger</a></p>
<p><a target="_blank" rel="noopener" href="https://go-review.googlesource.com/c/go/+/143157/">runtime: remove periodic scavenging</a></p>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>上面，我们知道了<code>pprof</code>抓的堆内存的大小和<code>RSS</code>不一致，有几种可能：</p>
<ol>
<li>是程序申请的内存还没有被<code>GC</code>。</li>
<li>内存虽然被<code>GO</code>执行了<code>GC</code>，但是可能并没有归还给操作系统（<code>scavenging</code>）。</li>
</ol>
<p>为了验证一下上面的结论，我上机器抓了下<code>heap</code>的统计：</p>
<pre><code>nx-x-x(lark.arch.dts@stock:prod):dts# curl http://ip:port/debug/pprof/heap?debug=1 | grep Heap
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0# 0xa47ba9        runtime/pprof.writeHeapInternal+0xc9                    /usr/local/go/src/runtime/pprof/pprof.go:566
#       0xa47a46        runtime/pprof.writeHeap+0x26                            /usr/local/go/src/runtime/pprof/pprof.go:536
100  913M    0  913M    0     0  86.8M      0 --:--:--  0:00:10 --:--:-- 90.6M# 0xa47ba9        runtime/pprof.writeHeapInternal+0xc9                    /usr/local/go/src/runtime/pprof/pprof.go:566
#       0xa47a46        runtime/pprof.writeHeap+0x26                            /usr/local/go/src/runtime/pprof/pprof.go:536
# HeapAlloc = 11406775960
# HeapSys = 13709377536
# HeapIdle = 2032746496
# HeapInuse = 11676631040
# HeapReleased = 167829504
# HeapObjects = 49932438
</code></pre>
<p>这里我主要关注几个参数：</p>
<p><a target="_blank" rel="noopener" href="https://github.com/golang/go/blob/master/src/runtime/mstats.go#L160">HeapInuse</a>： 堆上使用中的<code>mspan</code>大小。</p>
<p><a target="_blank" rel="noopener" href="https://github.com/golang/go/blob/master/src/runtime/mstats.go#L173">HeapReleased</a>：归还了多少内存给操作系统。</p>
<p><a target="_blank" rel="noopener" href="https://github.com/golang/go/blob/master/src/runtime/mstats.go#L145">HeapIdle</a>：空闲的<code>mspan</code>大小。<code>HeapIdle - HeapReleased</code> 等于<code>runtime</code>持有了多少个空闲的<code>mspan</code>，这部分还没有释放给操作系统，在<code>pprof</code>的<code>heap</code>火焰图里面是看不到这部分内存的。</p>
<pre><code>stats.HeapIdle = gcController.heapFree.load() + gcController.heapReleased.load()
</code></pre>
<p>上面我们获取机器的内存信息如下</p>
<pre><code>HeapInuse = 11676631040 ≈ 10.88G // 堆上使用内存的大小

HeapIdle - HeapReleased = 2032746496 - 167829504 ≈ 1.73G // 可以归还但是没有归还的内存
</code></pre>
<p>两个加起来，也差不多<code>12~13G</code>左右，所以容器的内存使用率是<code>80%</code>也是符合预期的。</p>
<p>还有个问题，为什么我们程序的<code>localcache</code>大小设置的只有了<code>6G</code>，实际<code>heap</code>使用了<code>10.88G</code>，因为<code>HeapInuse</code>除了程序真正使用的内存，还包括：</p>
<ol>
<li>程序释放的内存，但是还没有被<code>GC</code>。这部分内存还是算在<code>HeapInuse</code>中（这个应该是大头）。</li>
<li>上面说的<code>mspan</code>的<code>max waste</code>和<code>tail waste</code>这部分也在<code>HeapInuse</code>（这个应该很少）。</li>
<li>假设一个<code>8k</code>的<code>mspan</code>上只使用了一个大小为<code>8Byte</code>的<code>obj</code>，这个在<code>HeapInuse</code>会算<code>8K</code>。</li>
</ol>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p><code>golang</code>堆内存大小不一定跟<code>RSS</code>一致，它跟<code>GC</code>、<code>scavenging</code>时机有关。如果有大量<code>lcoalcache</code>申请释放，很可能导致<code>RSS</code>远远大于<code>heap</code>使用的大小。</p>
</article><section class="jump-container is-flex is-justify-content-space-between my-6"><!-- em is empty placeholder--><a class="button is-default" href="/2022/07/18/nonviolent-communication/" title="《非暴力沟通》"><i class="iconfont icon-prev mr-2 has-text-grey"></i><span class="has-text-weight-semibold">上一页: 《非暴力沟通》</span></a><a class="button is-default" href="/2022/05/25/mysql-insert-auto-incre/" title="MySQL 自增列 Duplicate Error 问题分析"><span class="has-text-weight-semibold">下一页: MySQL 自增列 Duplicate Error 问题分析</span><i class="iconfont icon-next ml-2 has-text-grey"></i></a></section><article class="mt-6 comment-container"><script async repo="fanlv/blog" src="https://utteranc.es/client.js" issue-term="pathname" theme="preferred-color-scheme"></script></article></div></div></main></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/fanlv"><i class="iconfont icon-github"></i></a><!-- Ins--><a title="instagram" target="_blank" rel="noopener nofollow" href="//www.instagram.com/fanlvlgh"><i class="iconfont icon-ins"></i></a><!-- RSS--><!-- 知乎--><!-- 领英--><!-- 脸书--></section><p><span>Copyright ©</span><span> Ryo 2022</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"></div><div><span>博学之，审问之，慎思之，明辨之，笃行之</span></div></footer><script async defer src="https://buttons.github.io/buttons.js"></script><script src="/js/post.js"></script></body></html>