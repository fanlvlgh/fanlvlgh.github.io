<!DOCTYPE html><html class="appearance-auto" lang="zh-CN"><head><meta charset="UTF-8"><title>《Redis核心技术与实战》</title><meta name="description" content="行万里路，读万卷书"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><script>var _hmt = _hmt || [];
(function() {
var hm = document.createElement("script");
hm.src = "https://hm.baidu.com/hm.js?" + '2c076421eb9f21a0a143f8ee9c4ab171';
var s = document.getElementsByTagName("script")[0];
s.parentNode.insertBefore(hm, s);
})();</script><!-- End Baidu Analytics --><meta name="referrer" content="no-referrer"><link rel="icon" href="/null"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/post.css"><link rel="stylesheet" href="/style/themes/highlight-theme-light.css"><script src="/js/highlight.pack.js"></script><meta name="description" content="数据结构Redis数据结构简单来说，底层数据结构一共有 6 种，分别是简单动态字符串、双向链表、压缩列表、哈希表、跳表和整数数组。它们和数据类型的对应关系如下图所示：

全局哈希表
因为这个哈希表保存了所有的键值对，所以，我也把它称为全局哈希表。哈希表的最大好处很明显，就是让我们可以用 O(1) 的时间复杂度来快速查找到键值对——我们只需要计算键的哈希值，就可以知道它所对应的哈希桶位置，然后就可以访问相应的 entry 元素。
渐进式 rehash简单来说就是在第二步拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entr.."><meta name="generator" content="Hexo 5.4.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">Ryo's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><div class="is-full-height" id="postTopic"><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">《Redis核心技术与实战》</p><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">点击返回顶部</p></div></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">首页</a></h3><h3 class="is-inline-block"><a href="/about">关于</a></h3><h3 class="is-inline-block"><a href="/archives">归档</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">首页</a></h3><h3 class="is-inline-block"><a href="/about">关于</a></h3><h3 class="is-inline-block"><a href="/archives">归档</a></h3></header><main><main class="container is-max-widescreen content section post-page pt-4 px-4"><div class="columns is-flex-desktop is-justify-content-center is-flex-direction-row-reverse"><div class="column is-3 is-hidden-mobile"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><span class="toc-text">数据结构</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><span class="toc-text">Redis数据结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%A8%E5%B1%80%E5%93%88%E5%B8%8C%E8%A1%A8"><span class="toc-text">全局哈希表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B8%90%E8%BF%9B%E5%BC%8F-rehash"><span class="toc-text">渐进式 rehash</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9F%A5%E6%89%BE%E5%A4%8D%E6%9D%82%E5%BA%A6"><span class="toc-text">查找复杂度</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Redis-IO-%E6%A8%A1%E5%9E%8B"><span class="toc-text">Redis IO 模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#AOF%E5%92%8CRDB"><span class="toc-text">AOF和RDB</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#AOF-%E9%87%8D%E5%86%99"><span class="toc-text">AOF 重写</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RDB"><span class="toc-text">RDB</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RBD%E6%98%AF%E4%B8%8D%E6%98%AF%E5%8F%AF%E4%BB%A5%E6%AF%8F%E7%A7%92%E5%81%9A%E4%B8%80%E6%AC%A1%E5%BF%AB%E7%85%A7%EF%BC%9F"><span class="toc-text">RBD是不是可以每秒做一次快照？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%AB%98%E5%8F%AF%E7%94%A8"><span class="toc-text">高可用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E4%BB%8E"><span class="toc-text">主从</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E4%BB%8E%E5%BA%93%E7%AC%AC%E4%B8%80%E6%AC%A1%E5%90%8C%E6%AD%A5%E7%9A%84%E6%B5%81%E7%A8%8B"><span class="toc-text">主从库第一次同步的流程</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%93%A8%E5%85%B5"><span class="toc-text">哨兵</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B"><span class="toc-text">哨兵机制的基本流程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E8%A7%82%E4%B8%8B%E7%BA%BF%E5%92%8C%E5%AE%A2%E8%A7%82%E4%B8%8B%E7%BA%BF"><span class="toc-text">主观下线和客观下线</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E9%80%89%E5%AE%9A%E6%96%B0%E4%B8%BB%E5%BA%93%EF%BC%9F"><span class="toc-text">如何选定新主库？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%93%A8%E5%85%B5%E5%9C%A8%E6%93%8D%E4%BD%9C%E4%B8%BB%E4%BB%8E%E5%88%87%E6%8D%A2%E7%9A%84%E8%BF%87%E7%A8%8B%E4%B8%AD%EF%BC%8C%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%83%BD%E5%90%A6%E6%AD%A3%E5%B8%B8%E5%9C%B0%E8%BF%9B%E8%A1%8C%E8%AF%B7%E6%B1%82%E6%93%8D%E4%BD%9C%EF%BC%9F"><span class="toc-text">哨兵在操作主从切换的过程中，客户端能否正常地进行请求操作？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E-pub-sub-%E6%9C%BA%E5%88%B6%E7%9A%84%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4%E7%BB%84%E6%88%90"><span class="toc-text">基于 pub&#x2F;sub 机制的哨兵集群组成</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%93%A8%E5%85%B5%E6%98%AF%E5%A6%82%E4%BD%95%E7%9F%A5%E9%81%93%E4%BB%8E%E5%BA%93%E7%9A%84-IP-%E5%9C%B0%E5%9D%80%E5%92%8C%E7%AB%AF%E5%8F%A3%E7%9A%84%E5%91%A2%EF%BC%9F"><span class="toc-text">哨兵是如何知道从库的 IP 地址和端口的呢？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E-pub-sub-%E6%9C%BA%E5%88%B6%E7%9A%84%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%BA%8B%E4%BB%B6%E9%80%9A%E7%9F%A5"><span class="toc-text">基于 pub&#x2F;sub 机制的客户端事件通知</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%94%B1%E5%93%AA%E4%B8%AA%E5%93%A8%E5%85%B5%E6%89%A7%E8%A1%8C%E4%B8%BB%E4%BB%8E%E5%88%87%E6%8D%A2%EF%BC%9F"><span class="toc-text">由哪个哨兵执行主从切换？</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Redis%E9%9B%86%E7%BE%A4"><span class="toc-text">Redis集群</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%88%87%E7%89%87%E5%92%8C%E5%AE%9E%E4%BE%8B%E7%9A%84%E5%AF%B9%E5%BA%94%E5%88%86%E5%B8%83%E5%85%B3%E7%B3%BB"><span class="toc-text">数据切片和实例的对应分布关系</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%A6%82%E4%BD%95%E5%AE%9A%E4%BD%8D%E6%95%B0%E6%8D%AE%EF%BC%9F"><span class="toc-text">客户端如何定位数据？</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%97%AE%E9%A2%98"><span class="toc-text">问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B4%E6%95%B0%E6%95%B0%E7%BB%84%E5%92%8C%E5%8E%8B%E7%BC%A9%E5%88%97%E8%A1%A8%E5%9C%A8%E6%9F%A5%E6%89%BE%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%E6%96%B9%E9%9D%A2%E5%B9%B6%E6%B2%A1%E6%9C%89%E5%BE%88%E5%A4%A7%E7%9A%84%E4%BC%98%E5%8A%BF%EF%BC%8C%E9%82%A3%E4%B8%BA%E4%BB%80%E4%B9%88-Redis-%E8%BF%98%E4%BC%9A%E6%8A%8A%E5%AE%83%E4%BB%AC%E4%BD%9C%E4%B8%BA%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%91%A2%EF%BC%9F"><span class="toc-text">整数数组和压缩列表在查找时间复杂度方面并没有很大的优势，那为什么 Redis 还会把它们作为底层数据结构呢？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Redis-%E5%9F%BA%E6%9C%AC-IO-%E6%A8%A1%E5%9E%8B%E4%B8%AD%E8%BF%98%E6%9C%89%E5%93%AA%E4%BA%9B%E6%BD%9C%E5%9C%A8%E7%9A%84%E6%80%A7%E8%83%BD%E7%93%B6%E9%A2%88%EF%BC%9F"><span class="toc-text">Redis 基本 IO 模型中还有哪些潜在的性能瓶颈？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#AOF-%E9%87%8D%E5%86%99%E8%BF%87%E7%A8%8B%E4%B8%AD%E6%9C%89%E6%B2%A1%E6%9C%89%E5%85%B6%E4%BB%96%E6%BD%9C%E5%9C%A8%E7%9A%84%E9%98%BB%E5%A1%9E%E9%A3%8E%E9%99%A9%EF%BC%9F"><span class="toc-text">AOF 重写过程中有没有其他潜在的阻塞风险？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#AOF-%E9%87%8D%E5%86%99%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E5%85%B1%E4%BA%AB%E4%BD%BF%E7%94%A8-AOF-%E6%9C%AC%E8%BA%AB%E7%9A%84%E6%97%A5%E5%BF%97%EF%BC%9F"><span class="toc-text">AOF 重写为什么不共享使用 AOF 本身的日志？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E4%B8%80%E4%B8%AA-2-%E6%A0%B8-CPU%E3%80%814GB-%E5%86%85%E5%AD%98%E3%80%81500GB-%E7%A3%81%E7%9B%98%E7%9A%84%E4%BA%91%E4%B8%BB%E6%9C%BA%E8%BF%90%E8%A1%8C-Redis%EF%BC%8CRedis-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E6%95%B0%E6%8D%AE%E9%87%8F%E5%A4%A7%E5%B0%8F%E5%B7%AE%E4%B8%8D%E5%A4%9A%E6%98%AF-2GB%E3%80%82%E5%BD%93%E6%97%B6-Redis-%E4%B8%BB%E8%A6%81%E4%BB%A5%E4%BF%AE%E6%94%B9%E6%93%8D%E4%BD%9C%E4%B8%BA%E4%B8%BB%EF%BC%8C%E5%86%99%E8%AF%BB%E6%AF%94%E4%BE%8B%E5%B7%AE%E4%B8%8D%E5%A4%9A%E5%9C%A8-8-2-%E5%B7%A6%E5%8F%B3%EF%BC%8C%E4%B9%9F%E5%B0%B1%E6%98%AF%E8%AF%B4%EF%BC%8C%E5%A6%82%E6%9E%9C%E6%9C%89-100-%E4%B8%AA%E8%AF%B7%E6%B1%82%EF%BC%8C80-%E4%B8%AA%E8%AF%B7%E6%B1%82%E6%89%A7%E8%A1%8C%E7%9A%84%E6%98%AF%E4%BF%AE%E6%94%B9%E6%93%8D%E4%BD%9C%E3%80%82%E5%9C%A8%E8%BF%99%E4%B8%AA%E5%9C%BA%E6%99%AF%E4%B8%8B%EF%BC%8C%E7%94%A8-RDB-%E5%81%9A%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%89%E4%BB%80%E4%B9%88%E9%A3%8E%E9%99%A9%E5%90%97%EF%BC%9F"><span class="toc-text">使用一个 2 核 CPU、4GB 内存、500GB 磁盘的云主机运行 Redis，Redis 数据库的数据量大小差不多是 2GB。当时 Redis 主要以修改操作为主，写读比例差不多在 8:2 左右，也就是说，如果有 100 个请求，80 个请求执行的是修改操作。在这个场景下，用 RDB 做持久化有什么风险吗？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%BB%E4%BB%8E%E5%BA%93%E9%97%B4%E7%9A%84%E5%A4%8D%E5%88%B6%E4%B8%8D%E4%BD%BF%E7%94%A8-AOF%EF%BC%9F"><span class="toc-text">为什么主从库间的复制不使用 AOF？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8%E4%B8%BB%E4%BB%8E%E5%88%87%E6%8D%A2%E8%BF%87%E7%A8%8B%E4%B8%AD%EF%BC%8C%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%83%BD%E5%90%A6%E6%AD%A3%E5%B8%B8%E5%9C%B0%E8%BF%9B%E8%A1%8C%E8%AF%B7%E6%B1%82%E6%93%8D%E4%BD%9C%E5%91%A2%EF%BC%9F"><span class="toc-text">在主从切换过程中，客户端能否正常地进行请求操作呢？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E6%9E%9C%E6%83%B3%E8%A6%81%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E4%B8%8D%E6%84%9F%E7%9F%A5%E6%9C%8D%E5%8A%A1%E7%9A%84%E4%B8%AD%E6%96%AD%EF%BC%8C%E8%BF%98%E9%9C%80%E8%A6%81%E5%93%A8%E5%85%B5%E6%88%96%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%86%8D%E5%81%9A%E4%BA%9B%E4%BB%80%E4%B9%88%E5%90%97%EF%BC%9F"><span class="toc-text">如果想要应用程序不感知服务的中断，还需要哨兵或客户端再做些什么吗？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%93%A8%E5%85%B5%E5%AE%9E%E4%BE%8B%E6%98%AF%E4%B8%8D%E6%98%AF%E8%B6%8A%E5%A4%9A%E8%B6%8A%E5%A5%BD%E5%91%A2%EF%BC%9F%E5%A6%82%E6%9E%9C%E5%90%8C%E6%97%B6%E8%B0%83%E5%A4%A7-down-after-milliseconds-%E5%80%BC%EF%BC%8C%E5%AF%B9%E5%87%8F%E5%B0%91%E8%AF%AF%E5%88%A4%E6%98%AF%E4%B8%8D%E6%98%AF%E4%B9%9F%E6%9C%89%E5%A5%BD%E5%A4%84%EF%BC%9F"><span class="toc-text">哨兵实例是不是越多越好呢？如果同时调大 down-after-milliseconds 值，对减少误判是不是也有好处？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88-Redis-%E4%B8%8D%E7%9B%B4%E6%8E%A5%E7%94%A8%E4%B8%80%E4%B8%AA%E8%A1%A8%EF%BC%8C%E6%8A%8A%E9%94%AE%E5%80%BC%E5%AF%B9%E5%92%8C%E5%AE%9E%E4%BE%8B%E7%9A%84%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB%E8%AE%B0%E5%BD%95%E4%B8%8B%E6%9D%A5%EF%BC%9F"><span class="toc-text">为什么 Redis 不直接用一个表，把键值对和实例的对应关系记录下来？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Redis-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E5%81%9A-rehash%EF%BC%9F"><span class="toc-text">Redis 什么时候做 rehash？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%87%87%E7%94%A8%E6%B8%90%E8%BF%9B%E5%BC%8F-hash-%E6%97%B6%EF%BC%8C%E5%A6%82%E6%9E%9C%E5%AE%9E%E4%BE%8B%E6%9A%82%E6%97%B6%E6%B2%A1%E6%9C%89%E6%94%B6%E5%88%B0%E6%96%B0%E8%AF%B7%E6%B1%82%EF%BC%8C%E6%98%AF%E4%B8%8D%E6%98%AF%E5%B0%B1%E4%B8%8D%E5%81%9A-rehash-%E4%BA%86%EF%BC%9F"><span class="toc-text">采用渐进式 hash 时，如果实例暂时没有收到新请求，是不是就不做 rehash 了？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E7%BA%BF%E7%A8%8B%E3%80%81%E5%AD%90%E8%BF%9B%E7%A8%8B%E5%92%8C%E5%90%8E%E5%8F%B0%E7%BA%BF%E7%A8%8B%E7%9A%84%E8%81%94%E7%B3%BB%E4%B8%8E%E5%8C%BA%E5%88%AB"><span class="toc-text">主线程、子进程和后台线程的联系与区别</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%99%E6%97%B6%E5%A4%8D%E5%88%B6%E7%9A%84%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6"><span class="toc-text">写时复制的底层实现机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#replication-buffer-%E5%92%8C-repl-backlog-buffer-%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-text">replication buffer 和 repl_backlog_buffer 的区别</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E6%88%98"><span class="toc-text">实战</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#SDS%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8D%A0%E7%A9%BA%E9%97%B4"><span class="toc-text">SDS为什么占空间</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%82%E6%AD%A5%E7%9A%84%E5%AD%90%E7%BA%BF%E7%A8%8B%E6%9C%BA%E5%88%B6"><span class="toc-text">异步的子线程机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%91%E6%A0%B8%E7%9A%84%E9%A3%8E%E9%99%A9%E5%92%8C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="toc-text">绑核的风险和解决方案</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%80%E4%B8%AA-Redis-%E5%AE%9E%E4%BE%8B%E5%AF%B9%E5%BA%94%E7%BB%91%E4%B8%80%E4%B8%AA%E7%89%A9%E7%90%86%E6%A0%B8"><span class="toc-text">一个 Redis 实例对应绑一个物理核</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%98%E5%8C%96-Redis-%E6%BA%90%E7%A0%81"><span class="toc-text">优化 Redis 源码</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%A2%E6%88%B7%E7%AB%AF%E8%BE%93%E5%85%A5%E5%92%8C%E8%BE%93%E5%87%BA%E7%BC%93%E5%86%B2%E5%8C%BA"><span class="toc-text">客户端输入和输出缓冲区</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E4%BA%8C"><span class="toc-text">问题二</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#CPU%E9%97%AE%E9%A2%98"><span class="toc-text">CPU问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Redis-%E5%8F%98%E6%85%A2%E7%9A%84%E6%83%85%E5%86%B5"><span class="toc-text">Redis 变慢的情况</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E4%B8%8D%E4%B8%80%E8%87%B4%E9%97%AE%E9%A2%98"><span class="toc-text">缓存不一致问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E3%80%81%E5%87%BB%E7%A9%BF%E3%80%81%E7%A9%BF%E9%80%8F"><span class="toc-text">缓存雪崩、击穿、穿透</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Redis-%E5%8F%AF%E4%BB%A5%E5%9C%A8%E7%A7%92%E6%9D%80%E5%9C%BA%E6%99%AF%E7%9A%84%E5%93%AA%E4%BA%9B%E7%8E%AF%E8%8A%82%E5%8F%91%E6%8C%A5%E4%BD%9C%E7%94%A8%EF%BC%9F"><span class="toc-text">Redis 可以在秒杀场景的哪些环节发挥作用？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%87%8F%E5%80%BE%E6%96%9C%E7%9A%84%E6%88%90%E5%9B%A0%EF%BC%9F"><span class="toc-text">数据量倾斜的成因？</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#bigkey-%E5%AF%BC%E8%87%B4%E5%80%BE%E6%96%9C"><span class="toc-text">bigkey 导致倾斜</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Slot-%E5%88%86%E9%85%8D%E4%B8%8D%E5%9D%87%E8%A1%A1%E5%AF%BC%E8%87%B4%E5%80%BE%E6%96%9C"><span class="toc-text">Slot 分配不均衡导致倾斜</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Hash-Tag-%E5%AF%BC%E8%87%B4%E5%80%BE%E6%96%9C"><span class="toc-text">Hash Tag 导致倾斜</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E8%AE%BF%E9%97%AE%E5%80%BE%E6%96%9C%E7%9A%84%E6%88%90%E5%9B%A0%E5%92%8C%E5%BA%94%E5%AF%B9%E6%96%B9%E6%B3%95%EF%BC%9F"><span class="toc-text">数据访问倾斜的成因和应对方法？</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis-Cluster-%E7%93%B6%E9%A2%88"><span class="toc-text">Redis Cluster 瓶颈</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E4%BE%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E9%A2%91%E7%8E%87"><span class="toc-text">实例间通信频率</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E9%99%8D%E4%BD%8E%E5%AE%9E%E4%BE%8B%E9%97%B4%E7%9A%84%E9%80%9A%E4%BF%A1%E5%BC%80%E9%94%80%EF%BC%9F"><span class="toc-text">如何降低实例间的通信开销？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis-6-0%E6%96%B0%E7%89%B9%E6%80%A7"><span class="toc-text">Redis 6.0新特性</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%8E%E5%8D%95%E7%BA%BF%E7%A8%8B%E5%A4%84%E7%90%86%E7%BD%91%E7%BB%9C%E8%AF%B7%E6%B1%82%E5%88%B0%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%A4%84%E7%90%86"><span class="toc-text">从单线程处理网络请求到多线程处理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis-%E5%92%8C-Memcached%E3%80%81RocksDB-%E7%9A%84%E5%AF%B9%E6%AF%94"><span class="toc-text">Redis 和 Memcached、RocksDB 的对比</span></a></li></ol></div><div class="column is-9"><header class="my-4"><a href="/tags/Note"><i class="tag post-item-tag">Note</i></a><a href="/tags/Redis"><i class="tag post-item-tag">Redis</i></a></header><h1 class="mt-0 mb-1 is-family-serif" id="postTitle">《Redis核心技术与实战》</h1><time class="has-text-grey" datetime="2021-02-10T10:32:31.000Z">2021-02-10</time><article class="mt-2 post-content"><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><h3 id="Redis数据结构"><a href="#Redis数据结构" class="headerlink" title="Redis数据结构"></a>Redis数据结构</h3><p>简单来说，底层数据结构一共有 6 种，分别是简单动态字符串、双向链表、压缩列表、哈希表、跳表和整数数组。它们和数据类型的对应关系如下图所示：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/12321605-e61bfa91dc198b1b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h3 id="全局哈希表"><a href="#全局哈希表" class="headerlink" title="全局哈希表"></a>全局哈希表</h3><p><img src="https://upload-images.jianshu.io/upload_images/12321605-8bd16b21ce7e3cb8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>因为这个哈希表保存了所有的键值对，所以，我也把它称为全局哈希表。哈希表的最大好处很明显，就是让我们可以用 O(1) 的时间复杂度来快速查找到键值对——我们只需要计算键的哈希值，就可以知道它所对应的哈希桶位置，然后就可以访问相应的 entry 元素。</p>
<h3 id="渐进式-rehash"><a href="#渐进式-rehash" class="headerlink" title="渐进式 rehash"></a>渐进式 rehash</h3><p>简单来说就是在第二步拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries。如下图所示：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/12321605-32a124b6b3d63095.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h3 id="查找复杂度"><a href="#查找复杂度" class="headerlink" title="查找复杂度"></a>查找复杂度</h3><p><img src="https://upload-images.jianshu.io/upload_images/12321605-5fa2f6205c0b216a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h3 id="Redis-IO-模型"><a href="#Redis-IO-模型" class="headerlink" title="Redis IO 模型"></a>Redis IO 模型</h3><p><img src="https://upload-images.jianshu.io/upload_images/12321605-d4a960937b69b70b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h2 id="AOF和RDB"><a href="#AOF和RDB" class="headerlink" title="AOF和RDB"></a>AOF和RDB</h2><h3 id="AOF-重写"><a href="#AOF-重写" class="headerlink" title="AOF 重写"></a>AOF 重写</h3><p><img src="https://upload-images.jianshu.io/upload_images/12321605-edb422acc9565202.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h3 id="RDB"><a href="#RDB" class="headerlink" title="RDB"></a>RDB</h3><p><img src="https://upload-images.jianshu.io/upload_images/12321605-b006d8a5dcf08c91.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image"></p>
<h3 id="RBD是不是可以每秒做一次快照？"><a href="#RBD是不是可以每秒做一次快照？" class="headerlink" title="RBD是不是可以每秒做一次快照？"></a>RBD是不是可以每秒做一次快照？</h3><p>对于快照来说，所谓“连拍”就是指连续地做快照。这样一来，快照的间隔时间变得很短，即使某一时刻发生宕机了，因为上一时刻快照刚执行，丢失的数据也不会太多。但是，这其中的快照间隔时间就很关键了。</p>
<p>这种想法其实是错误的。虽然 bgsave 执行时不阻塞主线程，但是，如果频繁地执行全量快照，也会带来两方面的开销。</p>
<p>一方面，频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。</p>
<p>另一方面，bgsave 子进程需要通过 fork 操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，但是，fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。如果频繁 fork 出 bgsave 子进程，这就会频繁阻塞主线程了（所以，在 Redis 中如果有一个 bgsave 在运行，就不会再启动第二个 bgsave 子进程）。那么，有什么其他好方法吗？</p>
<p>在第一次做完全量快照后，T1 和 T2 时刻如果再做快照，我们只需要将被修改的数据写入快照文件就行。但是，这么做的前提是，我们需要记住哪些数据被修改了。你可不要小瞧这个“记住”功能，它需要我们使用额外的元数据信息去记录哪些数据被修改了，这会带来额外的空间开销问题。如下图所示：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/12321605-f31c6ef2d97bbe72.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>如果我们对每一个键值对的修改，都做个记录，那么，如果有 1 万个被修改的键值对，我们就需要有 1 万条额外的记录。而且，有的时候，键值对非常小，比如只有 32 字节，而记录它被修改的元数据信息，可能就需要 8 字节，这样的画，为了“记住”修改，引入的额外空间开销比较大。这对于内存资源宝贵的 Redis 来说，有些得不偿失。</p>
<p>Redis 4.0 中提出了一个混合使用 AOF 日志和内存快照的方法。简单来说，内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。</p>
<p>如下图所示，T1 和 T2 时刻的修改，用 AOF 日志记录，等到第二次做全量快照时，就可以清空 AOF 日志，因为此时的修改都已经记录到快照中了，恢复时就不再用日志了。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/12321605-9a05c848340da60b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>这个方法既能享受到 RDB 文件快速恢复的好处，又能享受到 AOF 只记录操作命令的简单优势，颇有点“鱼和熊掌可以兼得”的感觉，建议你在实践中用起来。</p>
<h2 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h2><h3 id="主从"><a href="#主从" class="headerlink" title="主从"></a>主从</h3><h4 id="主从库第一次同步的流程"><a href="#主从库第一次同步的流程" class="headerlink" title="主从库第一次同步的流程"></a>主从库第一次同步的流程</h4><p><img src="https://upload-images.jianshu.io/upload_images/12321605-e75e5aff7114c3c1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>全量复制虽然耗时，但是对于从库来说，如果是第一次同步，全量复制是无法避免的，所以，我给你一个小建议：一个 Redis 实例的数据库不要太大，一个实例大小在几 GB 级别比较合适，这样可以减少 RDB 文件生成、传输和重新加载的开销。另外，为了避免多个从库同时和主库进行全量复制，给主库过大的同步压力，我们也可以采用“主 - 从 - 从”这一级联模式，来缓解主库的压力。</p>
<p>长连接复制是主从库正常运行后的常规同步阶段。在这个阶段中，主从库之间通过命令传播实现同步。不过，这期间如果遇到了网络断连，增量复制就派上用场了。我特别建议你留意一下 repl_backlog_size 这个配置参数。如果它配置得过小，在增量复制阶段，可能会导致从库的复制进度赶不上主库，进而导致从库重新进行全量复制。所以，通过调大这个参数，可以减少从库在网络断连时全量复制的风险。</p>
<h3 id="哨兵"><a href="#哨兵" class="headerlink" title="哨兵"></a>哨兵</h3><h4 id="哨兵机制的基本流程"><a href="#哨兵机制的基本流程" class="headerlink" title="哨兵机制的基本流程"></a>哨兵机制的基本流程</h4><p><img src="https://upload-images.jianshu.io/upload_images/12321605-6ded434e112a5e10.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h4 id="主观下线和客观下线"><a href="#主观下线和客观下线" class="headerlink" title="主观下线和客观下线"></a>主观下线和客观下线</h4><p><img src="https://upload-images.jianshu.io/upload_images/12321605-32899718bb7831f0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h4 id="如何选定新主库？"><a href="#如何选定新主库？" class="headerlink" title="如何选定新主库？"></a>如何选定新主库？</h4><p><img src="https://upload-images.jianshu.io/upload_images/12321605-ead329f8b53859e0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>所以，在选主时，除了要检查从库的当前在线状态，还要判断它之前的网络连接状态。如果从库总是和主库断连，而且断连次数超出了一定的阈值，我们就有理由相信，这个从库的网络状况并不是太好，就可以把这个从库筛掉了。</p>
<p>具体怎么判断呢？你使用配置项 down-after-milliseconds * 10。其中，down-after-milliseconds 是我们认定主从库断连的最大连接超时时间。如果在 down-after-milliseconds 毫秒内，主从节点都没有通过网络联系上，我们就可以认为主从节点断连了。如果发生断连的次数超过了 10 次，就说明这个从库的网络状况不好，不适合作为新主库。</p>
<p>接下来就要给剩余的从库打分了。我们可以分别按照三个规则依次进行三轮打分，这三个规则分别是从库优先级、从库复制进度以及从库 ID 号。只要在某一轮中，有从库得分最高，那么它就是主库了，选主过程到此结束。如果没有出现得分最高的从库，那么就继续进行下一轮。</p>
<p>第一轮：优先级最高的从库得分高。<br>用户可以通过 slave-priority 配置项，给不同的从库设置不同优先级。比如，你有两个从库，它们的内存大小不一样，你可以手动给内存大的实例设置一个高优先级。在选主时，哨兵会给优先级高的从库打高分，如果有一个从库优先级最高，那么它就是新主库了。如果从库的优先级都一样，那么哨兵开始第二轮打分。</p>
<p>第二轮：和旧主库同步程度最接近的从库得分高。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/12321605-2dbae6ae77988f1c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>当然，如果有两个从库的 slave_repl_offset 值大小是一样的（例如，从库 1 和从库 2 的 slave_repl_offset 值都是 990），我们就需要给它们进行第三轮打分了。</p>
<p>第三轮：ID 号小的从库得分高。</p>
<p>每个实例都会有一个 ID，这个 ID 就类似于这里的从库的编号。目前，Redis 在选主库时，有一个默认的规定：在优先级和复制进度都相同的情况下，ID 号最小的从库得分最高，会被选为新主库。</p>
<h4 id="哨兵在操作主从切换的过程中，客户端能否正常地进行请求操作？"><a href="#哨兵在操作主从切换的过程中，客户端能否正常地进行请求操作？" class="headerlink" title="哨兵在操作主从切换的过程中，客户端能否正常地进行请求操作？"></a>哨兵在操作主从切换的过程中，客户端能否正常地进行请求操作？</h4><p>哨兵在操作主从切换的过程中，客户端能否正常地进行请求操作？</p>
<p>如果客户端使用了读写分离，那么读请求可以在从库上正常执行，不会受到影响。但是由于此时主库已经挂了，而且哨兵还没有选出新的主库，所以在这期间写请求会失败，失败持续的时间 = 哨兵切换主从的时间 + 客户端感知到新主库 的时间。</p>
<p>如果不想让业务感知到异常，客户端只能把写失败的请求先缓存起来或写入消息队列中间件中，等哨兵切换完主从后，再把这些写请求发给新的主库，但这种场景只适合对写入请求返回值不敏感的业务，而且还需要业务层做适配，另外主从切换时间过长，也会导致客户端或消息队列中间件缓存写请求过多，切换完成之后重放这些请求的时间变长。</p>
<p>哨兵检测主库多久没有响应就提升从库为新的主库，这个时间是可以配置的（down-after-milliseconds参数）。配置的时间越短，哨兵越敏感，哨兵集群认为主库在短时间内连不上就会发起主从切换，这种配置很可能因为网络拥塞但主库正常而发生不必要的切换，当然，当主库真正故障时，因为切换得及时，对业务的影响最小。如果配置的时间比较长，哨兵越保守，这种情况可以减少哨兵误判的概率，但是主库故障发生时，业务写失败的时间也会比较久，缓存写请求数据量越多。</p>
<p>应用程序不感知服务的中断，还需要哨兵和客户端做些什么？当哨兵完成主从切换后，客户端需要及时感知到主库发生了变更，然后把缓存的写请求写入到新库中，保证后续写请求不会再受到影响，具体做法如下：</p>
<p>哨兵提升一个从库为新主库后，哨兵会把新主库的地址写入自己实例的pubsub（switch-master）中。客户端需要订阅这个pubsub，当这个pubsub有数据时，客户端就能感知到主库发生变更，同时可以拿到最新的主库地址，然后把写请求写到这个新主库即可，这种机制属于哨兵主动通知客户端。</p>
<p>如果客户端因为某些原因错过了哨兵的通知，或者哨兵通知后客户端处理失败了，安全起见，客户端也需要支持主动去获取最新主从的地址进行访问。</p>
<p>所以，客户端需要访问主从库时，不能直接写死主从库的地址了，而是需要从哨兵集群中获取最新的地址（sentinel get-master-addr-by-name命令），这样当实例异常时，哨兵切换后或者客户端断开重连，都可以从哨兵集群中拿到最新的实例地址。</p>
<p>一般Redis的SDK都提供了通过哨兵拿到实例地址，再访问实例的方式，我们直接使用即可，不需要自己实现这些逻辑。当然，对于只有主从实例的情况，客户端需要和哨兵配合使用，而在分片集群模式下，这些逻辑都可以做在proxy层，这样客户端也不需要关心这些逻辑了，Codis就是这么做的。</p>
<h4 id="基于-pub-sub-机制的哨兵集群组成"><a href="#基于-pub-sub-机制的哨兵集群组成" class="headerlink" title="基于 pub/sub 机制的哨兵集群组成"></a>基于 pub/sub 机制的哨兵集群组成</h4><p>哨兵实例之间可以相互发现，要归功于 Redis 提供的 pub/sub 机制，也就是发布 / 订阅机制。</p>
<p>哨兵只要和主库建立起了连接，就可以在主库上发布消息了，比如说发布它自己的连接信息（IP 和端口）。同时，它也可以从主库上订阅消息，获得其他哨兵发布的连接信息。当多个哨兵实例都在主库上做了发布和订阅操作后，它们之间就能知道彼此的 IP 地址和端口。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/12321605-6b84b62cde68cdf6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h4 id="哨兵是如何知道从库的-IP-地址和端口的呢？"><a href="#哨兵是如何知道从库的-IP-地址和端口的呢？" class="headerlink" title="哨兵是如何知道从库的 IP 地址和端口的呢？"></a>哨兵是如何知道从库的 IP 地址和端口的呢？</h4><p><img src="https://upload-images.jianshu.io/upload_images/12321605-94fc763588b6ce6c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h4 id="基于-pub-sub-机制的客户端事件通知"><a href="#基于-pub-sub-机制的客户端事件通知" class="headerlink" title="基于 pub/sub 机制的客户端事件通知"></a>基于 pub/sub 机制的客户端事件通知</h4><p>从本质上说，哨兵就是一个运行在特定模式下的 Redis 实例，只不过它并不服务请求操作，只是完成监控、选主和通知的任务。所以，每个哨兵实例也提供 pub/sub 机制，客户端可以从哨兵订阅消息。哨兵提供的消息订阅频道有很多，不同频道包含了主从库切换过程中的不同关键事件。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/12321605-07107bea955b9872.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>知道了这些频道之后，你就可以让客户端从哨兵这里订阅消息了。具体的操作步骤是，客户端读取哨兵的配置文件后，可以获得哨兵的地址和端口，和哨兵建立网络连接。然后，我们可以在客户端执行订阅命令，来获取不同的事件消息。</p>
<h4 id="由哪个哨兵执行主从切换？"><a href="#由哪个哨兵执行主从切换？" class="headerlink" title="由哪个哨兵执行主从切换？"></a>由哪个哨兵执行主从切换？</h4><p><img src="https://upload-images.jianshu.io/upload_images/12321605-03685d2753b96c9c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>一个哨兵获得了仲裁所需的赞成票数后，就可以标记主库为“客观下线”。这个所需的赞成票数是通过哨兵配置文件中的 quorum 配置项设定的。例如，现在有 5 个哨兵，quorum 配置的是 3，那么，一个哨兵需要 3 张赞成票，就可以标记主库为“客观下线”了。这 3 张赞成票包括哨兵自己的一张赞成票和另外两个哨兵的赞成票。</p>
<p>此时，这个哨兵就可以再给其他哨兵发送命令，表明希望由自己来执行主从切换，并让所有其他哨兵进行投票。这个投票过程称为“Leader 选举”。因为最终执行主从切换的哨兵称为 Leader，投票过程就是确定 Leader。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/12321605-52bac6f66d7248dd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h3 id="Redis集群"><a href="#Redis集群" class="headerlink" title="Redis集群"></a>Redis集群</h3><p><img src="https://upload-images.jianshu.io/upload_images/12321605-68315bffaa5f389c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>那么，在切片集群中，实例在为 5GB 数据生成 RDB 时，数据量就小了很多，fork 子进程一般不会给主线程带来较长时间的阻塞。采用多个实例保存数据切片后，我们既能保存 25GB 数据，又避免了 fork 子进程阻塞主线程而导致的响应突然变慢。</p>
<h4 id="数据切片和实例的对应分布关系"><a href="#数据切片和实例的对应分布关系" class="headerlink" title="数据切片和实例的对应分布关系"></a>数据切片和实例的对应分布关系</h4><p><img src="https://upload-images.jianshu.io/upload_images/12321605-0df4fbe7e3ae0c47.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h4 id="客户端如何定位数据？"><a href="#客户端如何定位数据？" class="headerlink" title="客户端如何定位数据？"></a>客户端如何定位数据？</h4><p><img src="https://upload-images.jianshu.io/upload_images/12321605-a98e6ff555602e61.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>需要注意的是，在上图中，当客户端给实例 2 发送命令时，<strong>Slot 2 中的数据已经全部迁移到了实例 3</strong>。在实际应用时，如果 Slot 2 中的数据比较多，就可能会出现一种情况：客户端向实例 2 发送请求，但此时，<strong>Slot 2 中的数据只有一部分迁移到了实例 3</strong>，还有部分数据没有迁移。在这种迁移部分完成的情况下，客户端就会收到<strong>一条 ASK 报错信息</strong>，如下所示：</p>
<p>和 MOVED 命令不同，ASK 命令并不会更新客户端缓存的哈希槽分配信息。所以，在上图中，如果客户端再次请求 Slot 2 中的数据，它还是会给实例 2 发送请求。这也就是说，ASK 命令的作用只是让客户端能给新实例发送一次请求，而不像 MOVED 命令那样，会更改本地缓存，让后续所有命令都发往新实例。</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><h3 id="整数数组和压缩列表在查找时间复杂度方面并没有很大的优势，那为什么-Redis-还会把它们作为底层数据结构呢？"><a href="#整数数组和压缩列表在查找时间复杂度方面并没有很大的优势，那为什么-Redis-还会把它们作为底层数据结构呢？" class="headerlink" title="整数数组和压缩列表在查找时间复杂度方面并没有很大的优势，那为什么 Redis 还会把它们作为底层数据结构呢？"></a>整数数组和压缩列表在查找时间复杂度方面并没有很大的优势，那为什么 Redis 还会把它们作为底层数据结构呢？</h3><p><img src="https://upload-images.jianshu.io/upload_images/12321605-6dba8a479077ed50.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>Redis 之所以采用不同的数据结构，其实是在性能和内存使用效率之间进行的平衡。</p>
<p>1、内存利用率，数组和压缩列表都是非常紧凑的数据结构，它比链表占用的内存要更少。Redis是内存数据库，大量数据存到内存中，此时需要做尽可能的优化，提高内存的利用率。<br>2、数组对CPU高速缓存支持更友好，所以Redis在设计时，集合数据元素较少情况下，默认采用内存紧凑排列的方式存储，同时利用CPU高速缓存不会降低访问速度。当数据元素超过设定阈值后，避免查询时间复杂度太高，转为哈希和跳表数据结构存储，保证查询效率。</p>
<h3 id="Redis-基本-IO-模型中还有哪些潜在的性能瓶颈？"><a href="#Redis-基本-IO-模型中还有哪些潜在的性能瓶颈？" class="headerlink" title="Redis 基本 IO 模型中还有哪些潜在的性能瓶颈？"></a>Redis 基本 IO 模型中还有哪些潜在的性能瓶颈？</h3><p>这个问题是希望你能进一步理解阻塞操作对 Redis 单线程性能的影响。在 Redis 基本 IO 模型中，主要是主线程在执行操作，任何耗时的操作，例如 bigkey、全量返回等操作，都是潜在的性能瓶颈。</p>
<ol>
<li>任意一个请求在server中一旦发生耗时，都会影响整个server的性能，也就是说后面的请求都要等前面这个耗时请求处理完成，自己才能被处理到。耗时的操作包括以下几种：<ul>
<li>操作bigkey：写入一个bigkey在分配内存时需要消耗更多的时间，同样，删除bigkey释放内存同样会产生耗时；</li>
<li>使用复杂度过高的命令：例如SORT/SUNION/ZUNIONSTORE，或者O(N)命令，但是N很大，例如lrange key 0 -1一次查询全量数据；</li>
<li>大量key集中过期：Redis的过期机制也是在主线程中执行的，大量key集中过期会导致处理一个请求时，耗时都在删除过期key，耗时变长；</li>
<li>淘汰策略：淘汰策略也是在主线程执行的，当内存超过Redis内存上限后，每次写入都需要淘汰一些key，也会造成耗时变长；</li>
<li>AOF刷盘开启always机制：每次写入都需要把这个操作刷到磁盘，写磁盘的速度远比写内存慢，会拖慢Redis的性能；</li>
<li>主从全量同步生成RDB：虽然采用fork子进程生成数据快照，但fork这一瞬间也是会阻塞整个线程的，实例越大，阻塞时间越久；</li>
</ul>
</li>
<li>并发量非常大时，单线程读写客户端IO数据存在性能瓶颈，虽然采用IO多路复用机制，但是读写客户端数据依旧是同步IO，只能单线程依次读取客户端的数据，无法利用到CPU多核。</li>
</ol>
<p>针对问题1，一方面需要业务人员去规避，一方面Redis在4.0推出了lazy-free机制，把bigkey释放内存的耗时操作放在了异步线程中执行，降低对主线程的影响。</p>
<p>针对问题2，Redis在6.0推出了多线程，可以在高并发场景下利用CPU多核多线程读写客户端数据，进一步提升server性能，当然，只是针对客户端的读写是并行的，每个命令的真正操作依旧是单线程的。</p>
<h3 id="AOF-重写过程中有没有其他潜在的阻塞风险？"><a href="#AOF-重写过程中有没有其他潜在的阻塞风险？" class="headerlink" title="AOF 重写过程中有没有其他潜在的阻塞风险？"></a>AOF 重写过程中有没有其他潜在的阻塞风险？</h3><p>风险一：Redis 主线程 fork 创建 bgrewriteaof 子进程时，内核需要创建用于管理子进程的相关数据结构，这些数据结构在操作系统中通常叫作进程控制块（Process Control Block，简称为 PCB）。内核要把主线程的 PCB 内容拷贝给子进程。这个创建和拷贝过程由内核执行，是会阻塞主线程的。而且，在拷贝过程中，子进程要拷贝父进程的页表，这个过程的耗时和 Redis 实例的内存大小有关。如果 Redis 实例内存大，页表就会大，fork 执行时间就会长，这就会给主线程带来阻塞风险。</p>
<p>风险二：bgrewriteaof 子进程会和主线程共享内存。当主线程收到新写或修改的操作时，主线程会申请新的内存空间，用来保存新写或修改的数据，如果操作的是 bigkey，也就是数据量大的集合类型数据，那么，主线程会因为申请大空间而面临阻塞风险。因为操作系统在分配内存空间时，有查找和锁的开销，这就会导致阻塞。</p>
<h3 id="AOF-重写为什么不共享使用-AOF-本身的日志？"><a href="#AOF-重写为什么不共享使用-AOF-本身的日志？" class="headerlink" title="AOF 重写为什么不共享使用 AOF 本身的日志？"></a>AOF 重写为什么不共享使用 AOF 本身的日志？</h3><p>如果都用 AOF 日志的话，主线程要写，bgrewriteaof 子进程也要写，这两者会竞争文件系统的锁，这就会对 Redis 主线程的性能造成影响。</p>
<h3 id="使用一个-2-核-CPU、4GB-内存、500GB-磁盘的云主机运行-Redis，Redis-数据库的数据量大小差不多是-2GB。当时-Redis-主要以修改操作为主，写读比例差不多在-8-2-左右，也就是说，如果有-100-个请求，80-个请求执行的是修改操作。在这个场景下，用-RDB-做持久化有什么风险吗？"><a href="#使用一个-2-核-CPU、4GB-内存、500GB-磁盘的云主机运行-Redis，Redis-数据库的数据量大小差不多是-2GB。当时-Redis-主要以修改操作为主，写读比例差不多在-8-2-左右，也就是说，如果有-100-个请求，80-个请求执行的是修改操作。在这个场景下，用-RDB-做持久化有什么风险吗？" class="headerlink" title="使用一个 2 核 CPU、4GB 内存、500GB 磁盘的云主机运行 Redis，Redis 数据库的数据量大小差不多是 2GB。当时 Redis 主要以修改操作为主，写读比例差不多在 8:2 左右，也就是说，如果有 100 个请求，80 个请求执行的是修改操作。在这个场景下，用 RDB 做持久化有什么风险吗？"></a>使用一个 2 核 CPU、4GB 内存、500GB 磁盘的云主机运行 Redis，Redis 数据库的数据量大小差不多是 2GB。当时 Redis 主要以修改操作为主，写读比例差不多在 8:2 左右，也就是说，如果有 100 个请求，80 个请求执行的是修改操作。在这个场景下，用 RDB 做持久化有什么风险吗？</h3><p>内存不足的风险：Redis fork 一个 bgsave 子进程进行 RDB 写入，如果主线程再接收到写操作，就会采用写时复制。写时复制需要给写操作的数据分配新的内存空间。本问题中写的比例为 80%，那么，在持久化过程中，为了保存 80% 写操作涉及的数据，写时复制机制会在实例内存中，为这些数据再分配新内存空间，分配的内存量相当于整个实例数据量的 80%，大约是 1.6GB，这样一来，整个系统内存的使用量就接近饱和了。此时，如果实例还有大量的新 key 写入或 key 修改，云主机内存很快就会被吃光。如果云主机开启了 Swap 机制，就会有一部分数据被换到磁盘上，当访问磁盘上的这部分数据时，性能会急剧下降。如果云主机没有开启 Swap，会直接触发 OOM，整个 Redis 实例会面临被系统 kill 掉的风险。</p>
<p>主线程和子进程竞争使用 CPU 的风险：生成 RDB 的子进程需要 CPU 核运行，主线程本身也需要 CPU 核运行，而且，如果 Redis 还启用了后台线程，此时，主线程、子进程和后台线程都会竞争 CPU 资源。由于云主机只有 2 核 CPU，这就会影响到主线程处理请求的速度。</p>
<h3 id="为什么主从库间的复制不使用-AOF？"><a href="#为什么主从库间的复制不使用-AOF？" class="headerlink" title="为什么主从库间的复制不使用 AOF？"></a>为什么主从库间的复制不使用 AOF？</h3><ol>
<li>RDB 文件是二进制文件，无论是要把 RDB 写入磁盘，还是要通过网络传输 RDB，IO 效率都比记录和传输 AOF 的高。</li>
<li>在从库端进行恢复时，用 RDB 的恢复效率要高于用 AOF。</li>
</ol>
<h3 id="在主从切换过程中，客户端能否正常地进行请求操作呢？"><a href="#在主从切换过程中，客户端能否正常地进行请求操作呢？" class="headerlink" title="在主从切换过程中，客户端能否正常地进行请求操作呢？"></a>在主从切换过程中，客户端能否正常地进行请求操作呢？</h3><p>主从集群一般是采用读写分离模式，当主库故障后，客户端仍然可以把读请求发送给从库，让从库服务。但是，对于写请求操作，客户端就无法执行了。</p>
<h3 id="如果想要应用程序不感知服务的中断，还需要哨兵或客户端再做些什么吗？"><a href="#如果想要应用程序不感知服务的中断，还需要哨兵或客户端再做些什么吗？" class="headerlink" title="如果想要应用程序不感知服务的中断，还需要哨兵或客户端再做些什么吗？"></a>如果想要应用程序不感知服务的中断，还需要哨兵或客户端再做些什么吗？</h3><p>一方面，客户端需要能缓存应用发送的写请求。只要不是同步写操作（Redis 应用场景一般也没有同步写），写请求通常不会在应用程序的关键路径上，所以，客户端缓存写请求后，给应用程序返回一个确认就行。</p>
<p>另一方面，主从切换完成后，客户端要能和新主库重新建立连接，哨兵需要提供订阅频道，让客户端能够订阅到新主库的信息。同时，客户端也需要能主动和哨兵通信，询问新主库的信息。</p>
<h3 id="哨兵实例是不是越多越好呢？如果同时调大-down-after-milliseconds-值，对减少误判是不是也有好处？"><a href="#哨兵实例是不是越多越好呢？如果同时调大-down-after-milliseconds-值，对减少误判是不是也有好处？" class="headerlink" title="哨兵实例是不是越多越好呢？如果同时调大 down-after-milliseconds 值，对减少误判是不是也有好处？"></a>哨兵实例是不是越多越好呢？如果同时调大 down-after-milliseconds 值，对减少误判是不是也有好处？</h3><p>哨兵实例越多，误判率会越低，但是在判定主库下线和选举 Leader 时，实例需要拿到的赞成票数也越多，等待所有哨兵投完票的时间可能也会相应增加，主从库切换的时间也会变长，客户端容易堆积较多的请求操作，可能会导致客户端请求溢出，从而造成请求丢失。如果业务层对 Redis 的操作有响应时间要求，就可能会因为新主库一直没有选定，新操作无法执行而发生超时报警。</p>
<p>调大 down-after-milliseconds 后，可能会导致这样的情况：主库实际已经发生故障了，但是哨兵过了很长时间才判断出来，这就会影响到 Redis 对业务的可用性。</p>
<h3 id="为什么-Redis-不直接用一个表，把键值对和实例的对应关系记录下来？"><a href="#为什么-Redis-不直接用一个表，把键值对和实例的对应关系记录下来？" class="headerlink" title="为什么 Redis 不直接用一个表，把键值对和实例的对应关系记录下来？"></a>为什么 Redis 不直接用一个表，把键值对和实例的对应关系记录下来？</h3><p>如果使用表记录键值对和实例的对应关系，一旦键值对和实例的对应关系发生了变化（例如实例有增减或者数据重新分布），就要修改表。如果是单线程操作表，那么所有操作都要串行执行，性能慢；如果是多线程操作表，就涉及到加锁开销。此外，如果数据量非常大，使用表记录键值对和实例的对应关系，需要的额外存储空间也会增加。</p>
<p>基于哈希槽计算时，虽然也要记录哈希槽和实例的对应关系，但是哈希槽的个数要比键值对的个数少很多，无论是修改哈希槽和实例的对应关系，还是使用额外空间存储哈希槽和实例的对应关系，都比直接记录键值对和实例的关系的开销小得多。</p>
<h3 id="Redis-什么时候做-rehash？"><a href="#Redis-什么时候做-rehash？" class="headerlink" title="Redis 什么时候做 rehash？"></a>Redis 什么时候做 rehash？</h3><p>Redis 会使用装载因子（load factor）来判断是否需要做 rehash。装载因子的计算方式是，哈希表中所有 entry 的个数除以哈希表的哈希桶个数。Redis 会根据装载因子的两种情况，来触发 rehash 操作：</p>
<ul>
<li>装载因子≥1，同时，哈希表被允许进行 rehash；</li>
<li>装载因子≥5。</li>
</ul>
<p>在第一种情况下，如果装载因子等于 1，同时我们假设，所有键值对是平均分布在哈希表的各个桶中的，那么，此时，哈希表可以不用链式哈希，因为一个哈希桶正好保存了一个键值对。</p>
<p>但是，如果此时再有新的数据写入，哈希表就要使用链式哈希了，这会对查询性能产生影响。在进行 RDB 生成和 AOF 重写时，哈希表的 rehash 是被禁止的，这是为了避免对 RDB 和 AOF 重写造成影响。如果此时，Redis 没有在生成 RDB 和重写 AOF，那么，就可以进行 rehash。否则的话，再有数据写入时，哈希表就要开始使用查询较慢的链式哈希了。</p>
<p>在第二种情况下，也就是装载因子大于等于 5 时，就表明当前保存的数据量已经远远大于哈希桶的个数，哈希桶里会有大量的链式哈希存在，性能会受到严重影响，此时，就立马开始做 rehash。</p>
<h3 id="采用渐进式-hash-时，如果实例暂时没有收到新请求，是不是就不做-rehash-了？"><a href="#采用渐进式-hash-时，如果实例暂时没有收到新请求，是不是就不做-rehash-了？" class="headerlink" title="采用渐进式 hash 时，如果实例暂时没有收到新请求，是不是就不做 rehash 了？"></a>采用渐进式 hash 时，如果实例暂时没有收到新请求，是不是就不做 rehash 了？</h3><p>其实不是的。Redis 会执行定时任务，定时任务中就包含了 rehash 操作。所谓的定时任务，就是按照一定频率（例如每 100ms/ 次）执行的任务。</p>
<p>在 rehash 被触发后，即使没有收到新请求，Redis 也会定时执行一次 rehash 操作，而且，每次执行时长不会超过 1ms，以免对其他任务造成影响。</p>
<h3 id="主线程、子进程和后台线程的联系与区别"><a href="#主线程、子进程和后台线程的联系与区别" class="headerlink" title="主线程、子进程和后台线程的联系与区别"></a>主线程、子进程和后台线程的联系与区别</h3><p><img src="https://upload-images.jianshu.io/upload_images/12321605-d4f082cb19238d2a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>在主线程中，我们还可以使用 fork 创建子进程，或是使用 pthread_create 创建线程。下面我先介绍下 Redis 中用 fork 创建的子进程有哪些。</p>
<ul>
<li>创建 RDB 的后台子进程，同时由它负责在主从同步时传输 RDB 给从库；</li>
<li>通过无盘复制方式传输 RDB 的子进程；</li>
<li>bgrewriteaof 子进程。</li>
</ul>
<h3 id="写时复制的底层实现机制"><a href="#写时复制的底层实现机制" class="headerlink" title="写时复制的底层实现机制"></a>写时复制的底层实现机制</h3><p><img src="https://upload-images.jianshu.io/upload_images/12321605-ed6ecd25a95cdb7e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h3 id="replication-buffer-和-repl-backlog-buffer-的区别"><a href="#replication-buffer-和-repl-backlog-buffer-的区别" class="headerlink" title="replication buffer 和 repl_backlog_buffer 的区别"></a>replication buffer 和 repl_backlog_buffer 的区别</h3><p>总的来说，replication buffer 是主从库在进行全量复制时，主库上用于和从库连接的客户端的 buffer，而 repl_backlog_buffer 是为了支持从库增量复制，主库上用于持续保存写操作的一块专用 buffer。</p>
<p>Redis 主从库在进行复制时，当主库要把全量复制期间的写操作命令发给从库时，主库会先创建一个客户端，用来连接从库，然后通过这个客户端，把写操作命令发给从库。在内存中，主库上的客户端就会对应一个 buffer，这个 buffer 就被称为 replication buffer。Redis 通过 client_buffer 配置项来控制这个 buffer 的大小。主库会给每个从库建立一个客户端，所以 replication buffer 不是共享的，而是每个从库都有一个对应的客户端。</p>
<p>repl_backlog_buffer 是一块专用 buffer，在 Redis 服务器启动后，开始一直接收写操作命令，这是所有从库共享的。主库和从库会各自记录自己的复制进度，所以，不同的从库在进行恢复时，会把自己的复制进度（slave_repl_offset）发给主库，主库就可以和它独立同步。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/12321605-bee7dca00a820694.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h2 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h2><h3 id="SDS为什么占空间"><a href="#SDS为什么占空间" class="headerlink" title="SDS为什么占空间"></a>SDS为什么占空间</h3><p><img src="https://upload-images.jianshu.io/upload_images/12321605-fee6ccdb8387fb15.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>因为 10 位数的图片 ID 和图片存储对象 ID 是 Long 类型整数，所以可以直接用 int 编码的 RedisObject 保存。每个 int 编码的 RedisObject 元数据部分占 8 字节，指针部分被直接赋值为 8 字节的整数了。此时，每个 ID 会使用 16 字节，加起来一共是 32 字节。但是，另外的 32 字节去哪儿了呢？</p>
<p>我在第 2 讲中说过，Redis 会使用一个全局哈希表保存所有键值对，哈希表的每一项是一个 dictEntry 的结构体，用来指向一个键值对。dictEntry 结构中有三个 8 字节的指针，分别指向 key、value 以及下一个 dictEntry，三个指针共 24 字节，如下图所示：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/12321605-0ca80d257ebf049c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>但是，这三个指针只有 24 字节，为什么会占用了 32 字节呢？这就要提到 Redis 使用的内存分配库 jemalloc 了。</p>
<p>jemalloc 在分配内存时，会根据我们申请的字节数 N，找一个比 N 大，但是最接近 N 的 2 的幂次数作为分配的空间，这样可以减少频繁分配的次数。</p>
<p>举个例子。如果你申请 6 字节空间，jemalloc 实际会分配 8 字节空间；如果你申请 24 字节空间，jemalloc 则会分配 32 字节。所以，在我们刚刚说的场景里，dictEntry 结构就占用了 32 字节。</p>
<p>你看，明明有效信息只有 16 字节，使用 String 类型保存时，却需要 64 字节的内存空间，有 48 字节都没有用于保存实际的数据。我们来换算下，如果要保存的图片有 1 亿张，那么 1 亿条的图片 ID 记录就需要 6.4GB 内存空间，其中有 4.8GB 的内存空间都用来保存元数据了，额外的内存空间开销很大。那么，有没有更加节省内存的方法呢？</p>
<h3 id="异步的子线程机制"><a href="#异步的子线程机制" class="headerlink" title="异步的子线程机制"></a>异步的子线程机制</h3><p>Redis 主线程启动后，会使用操作系统提供的 pthread_create 函数创建 3 个子线程，分别由它们负责 AOF 日志写操作、键值对删除以及文件关闭的异步执行。</p>
<p>主线程通过一个链表形式的任务队列和子线程进行交互。当收到键值对删除和清空数据库的操作时，主线程会把这个操作封装成一个任务，放入到任务队列中，然后给客户端返回一个完成信息，表明删除已经完成。</p>
<p>但实际上，这个时候删除还没有执行，等到后台子线程从任务队列中读取任务后，才开始实际删除键值对，并释放相应的内存空间。因此，我们把这种异步删除也称为惰性删除（lazy free）。此时，删除或清空操作不会阻塞主线程，这就避免了对主线程的性能影响。</p>
<p>和惰性删除类似，当 AOF 日志配置成 everysec 选项后，主线程会把 AOF 写日志操作封装成一个任务，也放到任务队列中。后台子线程读取任务后，开始自行写入 AOF 日志，这样主线程就不用一直等待 AOF 日志写完了。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/12321605-d275c2b8293b9f09.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>这里有个地方需要你注意一下，异步的键值对删除和数据库清空操作是 Redis 4.0 后提供的功能，Redis 也提供了新的命令来执行这两个操作。</p>
<ul>
<li>键值对删除：当你的集合类型中有大量元素（例如有百万级别或千万级别元素）需要删除时，我建议你使用 UNLINK 命令。</li>
<li>清空数据库：可以在 FLUSHDB 和 FLUSHALL 命令后加上 ASYNC 选项，这样就可以让后台子线程异步地清空数据库，如下所示：</li>
</ul>
<h3 id="绑核的风险和解决方案"><a href="#绑核的风险和解决方案" class="headerlink" title="绑核的风险和解决方案"></a>绑核的风险和解决方案</h3><p>当我们把 Redis 实例绑到一个 CPU 逻辑核上时，就会导致子进程、后台线程和 Redis 主线程竞争 CPU 资源，一旦子进程或后台线程占用 CPU 时，主线程就会被阻塞，导致 Redis 请求延迟增加。</p>
<h4 id="一个-Redis-实例对应绑一个物理核"><a href="#一个-Redis-实例对应绑一个物理核" class="headerlink" title="一个 Redis 实例对应绑一个物理核"></a>一个 Redis 实例对应绑一个物理核</h4><p><img src="https://upload-images.jianshu.io/upload_images/12321605-9bd83bc480efbf44.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<pre><code>lscpu

Architecture: x86_64
...
NUMA node0 CPU(s): 0-5,12-17
NUMA node1 CPU(s): 6-11,18-23
...
</code></pre>
<p>我们还是以刚才的 NUMA 架构为例，NUMA node0 的 CPU 核编号是 0 到 5、12 到 17。其中，编号 0 和 12、1 和 13、2 和 14 等都是表示一个物理核的 2 个逻辑核。所以，在绑核时，我们使用属于同一个物理核的 2 个逻辑核进行绑核操作。例如，我们执行下面的命令，就把 Redis 实例绑定到了逻辑核 0 和 12 上，而这两个核正好都属于物理核 1。</p>
<pre><code>taskset -c 0,12 ./redis-server
</code></pre>
<p>和只绑一个逻辑核相比，把 Redis 实例和物理核绑定，可以让主线程、子进程、后台线程共享使用 2 个逻辑核，可以在一定程度上缓解 CPU 资源竞争。但是，因为只用了 2 个逻辑核，它们相互之间的 CPU 竞争仍然还会存在。如果你还想进一步减少 CPU 竞争，我再给你介绍一种方案。</p>
<h4 id="优化-Redis-源码"><a href="#优化-Redis-源码" class="headerlink" title="优化 Redis 源码"></a>优化 Redis 源码</h4><p>通过编程实现绑核时，要用到操作系统提供的 1 个数据结构 cpu_set_t 和 3 个函数 CPU_ZERO、CPU_SET 和 sched_setaffinity，我先来解释下它们。</p>
<ul>
<li>cpu_set_t 数据结构：是一个位图，每一位用来表示服务器上的一个 CPU 逻辑核。</li>
<li>CPU_ZERO 函数：以 cpu_set_t 结构的位图为输入参数，把位图中所有的位设置为 0。</li>
<li>CPU_SET 函数：以 CPU 逻辑核编号和 cpu_set_t 位图为参数，把位图中和输入的逻辑核编号对应的位设置为 </li>
<li>sched_setaffinity 函数：以进程 / 线程 ID 号和 cpu_set_t 为参数，检查 cpu_set_t 中哪一位为 1，就把输入的 ID 号所代表的进程 / 线程绑在对应的逻辑核上。</li>
</ul>
<p>那么，怎么在编程时把这三个函数结合起来实现绑核呢？很简单，我们分四步走就行。</p>
<ul>
<li>第一步：创建一个 cpu_set_t 结构的位图变量；</li>
<li>第二步：使用 CPU_ZERO 函数，把 cpu_set_t 结构的位图所有的位都设置为 0；</li>
<li>第三步：根据要绑定的逻辑核编号，使用 CPU_SET 函数，把 cpu_set_t 结构的位图相应位设置为 1；</li>
<li>第四步：使用 sched_setaffinity 函数，把程序绑定在 cpu_set_t 结构位图中为 1 的逻辑核上。</li>
</ul>
<p>先说后台线程。为了让你更好地理解编程实现绑核，你可以看下这段示例代码，它实现了为线程绑核的操作：</p>
<pre><code>//线程函数
void worker(int bind_cpu){
    cpu_set_t cpuset;  //创建位图变量
    CPU_ZERO(&amp;cpu_set); //位图变量所有位设置0
    CPU_SET(bind_cpu, &amp;cpuset); //根据输入的bind_cpu编号，把位图对应为设置为1
    sched_setaffinity(0, sizeof(cpuset), &amp;cpuset); //把程序绑定在cpu_set_t结构位图中为1的逻辑核

    //实际线程函数工作
}

int main(){
    pthread_t pthread1
    //把创建的pthread1绑在编号为3的逻辑核上
    pthread_create(&amp;pthread1, NULL, (void *)worker, 3);
}
</code></pre>
<p>对于 Redis 来说，它是在 bio.c 文件中的 bioProcessBackgroundJobs 函数中创建了后台线程。bioProcessBackgroundJobs 函数类似于刚刚的例子中的 worker 函数，在这个函数中实现绑核四步操作，就可以把后台线程绑到和主线程不同的核上了。</p>
<p>和给线程绑核类似，当我们使用 fork 创建子进程时，也可以把刚刚说的四步操作实现在 fork 后的子进程代码中，示例代码如下：</p>
<pre><code>int main(){
   //用fork创建一个子进程
   pid_t p = fork();
   if(p &lt; 0){
      printf(" fork error\n");
   }
   //子进程代码部分
   else if(!p){
      cpu_set_t cpuset;  //创建位图变量
      CPU_ZERO(&amp;cpu_set); //位图变量所有位设置0
      CPU_SET(3, &amp;cpuset); //把位图的第3位设置为1
      sched_setaffinity(0, sizeof(cpuset), &amp;cpuset);  //把程序绑定在3号逻辑核
      //实际子进程工作
      exit(0);
   }
   ...
}
</code></pre>
<p>对于 Redis 来说，生成 RDB 和 AOF 日志重写的子进程分别是下面两个文件的函数中实现的。</p>
<ul>
<li>rdb.c 文件：rdbSaveBackground 函数；</li>
<li>aof.c 文件：rewriteAppendOnlyFileBackground 函数。</li>
</ul>
<h3 id="客户端输入和输出缓冲区"><a href="#客户端输入和输出缓冲区" class="headerlink" title="客户端输入和输出缓冲区"></a>客户端输入和输出缓冲区</h3><p><img src="https://upload-images.jianshu.io/upload_images/12321605-97f0471c6cad0bcc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>我们前面已经分析过了，输入缓冲区就是用来暂存客户端发送的请求命令的，所以可能导致溢出的情况主要是下面两种：</p>
<ul>
<li>写入了 bigkey，比如一下子写入了多个百万级别的集合类型数据；</li>
<li>服务器端处理请求的速度过慢，例如，Redis 主线程出现了间歇性阻塞，无法及时处理正常发送的请求，导致客户端发送的请求在缓冲区越积越多。</li>
</ul>
<p>所以，我们必须得想办法避免输入缓冲区溢出。我们可以从两个角度去考虑如何避免，一是把缓冲区调大，二是从数据命令的发送和处理速度入手。</p>
<p>那什么情况下会发生输出缓冲区溢出呢？ 我为你总结了三种：</p>
<ul>
<li>服务器端返回 bigkey 的大量结果；</li>
<li>执行了 MONITOR 命令；</li>
<li>缓冲区大小设置得不合理。</li>
</ul>
<p>我们来总结下如何应对输出缓冲区溢出：</p>
<ul>
<li>避免 bigkey 操作返回大量数据结果；</li>
<li>避免在线上环境中持续使用 MONITOR 命令。</li>
<li>使用 client-output-buffer-limit 设置合理的缓冲区大小上限，或是缓冲区连续写入时间和写入量上限。</li>
</ul>
<p>现在，从缓冲区溢出对 Redis 的影响的角度，我再把这四个缓冲区分成两类做个总结。</p>
<ul>
<li>缓冲区溢出导致网络连接关闭：普通客户端、订阅客户端，以及从节点客户端，它们使用的缓冲区，本质上都是 Redis 客户端和服务器端之间，或是主从节点之间为了传输命令数据而维护的。这些缓冲区一旦发生溢出，处理机制都是直接把客户端和服务器端的连接，或是主从节点间的连接关闭。网络连接关闭造成的直接影响，就是业务程序无法读写 Redis，或者是主从节点全量同步失败，需要重新执行。</li>
<li>缓冲区溢出导致命令数据丢失：主节点上的复制积压缓冲区属于环形缓冲区，一旦发生溢出，新写入的命令数据就会覆盖旧的命令数据，导致旧命令数据的丢失，进而导致主从节点重新进行全量复制。</li>
</ul>
<h3 id="问题二"><a href="#问题二" class="headerlink" title="问题二"></a>问题二</h3><h4 id="CPU问题"><a href="#CPU问题" class="headerlink" title="CPU问题"></a>CPU问题</h4><p>在一台有 2 个 CPU Socket（每个 Socket 8 个物理核）的服务器上，我们部署了有 8 个实例的 Redis 切片集群（8 个实例都为主节点，没有主备关系），现在有两个方案：</p>
<ul>
<li>在同一个 CPU Socket 上运行 8 个实例，并和 8 个 CPU 核绑定；</li>
<li>在 2 个 CPU Socket 上各运行 4 个实例，并和相应 Socket 上的核绑定。</li>
</ul>
<p>如果不考虑网络数据读取的影响，你会选择哪个方案呢？</p>
<p>答案：建议使用第二个方案，主要有两方面的原因。</p>
<ol>
<li>同一个 CPU Socket 上的进程，会共享 L3 缓存。如果把 8 个实例都部署在同一个 Socket 上，它们会竞争 L3 缓存，这就会导致它们的 L3 缓存命中率降低，影响访问性能。</li>
<li>同一个 CPU Socket 上的进程，会使用同一个 Socket 上的内存空间。8 个实例共享同一个 Socket 上的内存空间，肯定会竞争内存资源。如果有实例保存的数据量大，其他实例能用到的内存空间可能就不够了，此时，其他实例就会跨 Socket 申请内存，进而造成跨 Socket 访问内存，造成实例的性能降低。</li>
</ol>
<h4 id="Redis-变慢的情况"><a href="#Redis-变慢的情况" class="headerlink" title="Redis 变慢的情况"></a>Redis 变慢的情况</h4><ol>
<li>使用复杂度过高的命令或一次查询全量数据；</li>
<li>操作 bigkey；</li>
<li>大量 key 集中过期；</li>
<li>内存达到 maxmemory；</li>
<li>客户端使用短连接和 Redis 相连；</li>
<li>当 Redis 实例的数据量大时，无论是生成 RDB，还是 AOF 重写，都会导致 fork 耗时严重；</li>
<li>AOF 的写回策略为 always，导致每个操作都要同步刷回磁盘；</li>
<li>Redis 实例运行机器的内存不足，导致 swap 发生，Redis 需要到 swap 分区读取数据；</li>
<li>进程绑定 CPU 不合理；</li>
<li>Redis 实例运行机器上开启了透明内存大页机制；</li>
<li>网卡压力过大。</li>
</ol>
<h4 id="缓存不一致问题"><a href="#缓存不一致问题" class="headerlink" title="缓存不一致问题"></a>缓存不一致问题</h4><p><img src="https://upload-images.jianshu.io/upload_images/12321605-d0544ead210840e2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h4 id="缓存雪崩、击穿、穿透"><a href="#缓存雪崩、击穿、穿透" class="headerlink" title="缓存雪崩、击穿、穿透"></a>缓存雪崩、击穿、穿透</h4><p><img src="https://upload-images.jianshu.io/upload_images/12321605-6173168179abd2f4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h4 id="Redis-可以在秒杀场景的哪些环节发挥作用？"><a href="#Redis-可以在秒杀场景的哪些环节发挥作用？" class="headerlink" title="Redis 可以在秒杀场景的哪些环节发挥作用？"></a>Redis 可以在秒杀场景的哪些环节发挥作用？</h4><p>我们一般可以把秒杀活动分成三个阶段。在每一个阶段，Redis 所发挥的作用也不一样。</p>
<p>第一阶段是秒杀活动前。</p>
<p>在这个阶段，用户会不断刷新商品详情页，这会导致详情页的瞬时请求量剧增。这个阶段的应对方案，一般是尽量把商品详情页的页面元素静态化，然后使用 CDN 或是浏览器把这些静态化的元素缓存起来。这样一来，秒杀前的大量请求可以直接由 CDN 或是浏览器缓存服务，不会到达服务器端了，这就减轻了服务器端的压力。</p>
<p>在这个阶段，有 CDN 和浏览器缓存服务请求就足够了，我们还不需要使用 Redis。</p>
<p>第二阶段是秒杀活动开始。</p>
<p>此时，大量用户点击商品详情页上的秒杀按钮，会产生大量的并发请求查询库存。一旦某个请求查询到有库存，紧接着系统就会进行库存扣减。然后，系统会生成实际订单，并进行后续处理，例如订单支付和物流服务。如果请求查不到库存，就会返回。用户通常会继续点击秒杀按钮，继续查询库存。</p>
<p>简单来说，这个阶段的操作就是三个：库存查验、库存扣减和订单处理。因为每个秒杀请求都会查询库存，而请求只有查到有库存余量后，后续的库存扣减和订单处理才会被执行。所以，这个阶段中最大的并发压力都在库存查验操作上。</p>
<p>为了支撑大量高并发的库存查验请求，我们需要在这个环节使用 Redis 保存库存量，这样一来，请求可以直接从 Redis 中读取库存并进行查验。</p>
<p>那么，库存扣减和订单处理是否都可以交给后端的数据库来执行呢?</p>
<p>其实，订单处理可以在数据库中执行，但库存扣减操作，不能交给后端数据库处理。</p>
<p>在数据库中处理订单的原因比较简单，我先说下。</p>
<p>订单处理会涉及支付、商品出库、物流等多个关联操作，这些操作本身涉及数据库中的多张数据表，要保证处理的事务性，需要在数据库中完成。而且，订单处理时的请求压力已经不大了，数据库可以支撑这些订单处理请求。</p>
<p>那为啥库存扣减操作不能在数据库执行呢？这是因为，一旦请求查到有库存，就意味着发送该请求的用户获得了商品的购买资格，用户就会下单了。同时，商品的库存余量也需要减少一个。如果我们把库存扣减的操作放到数据库执行，会带来两个问题。</p>
<ol>
<li>额外的开销。Redis 中保存了库存量，而库存量的最新值又是数据库在维护，所以数据库更新后，还需要和 Redis 进行同步，这个过程增加了额外的操作逻辑，也带来了额外的开销。</li>
<li>下单量超过实际库存量，出现超售。由于数据库的处理速度较慢，不能及时更新库存余量，这就会导致大量库存查验的请求读取到旧的库存值，并进行下单。此时，就会出现下单数量大于实际的库存量，导致出现超售，这就不符合业务层的要求了。</li>
</ol>
<p>所以，我们就需要直接在 Redis 中进行库存扣减。具体的操作是，当库存查验完成后，一旦库存有余量，我们就立即在 Redis 中扣减库存。而且，为了避免请求查询到旧的库存值，库存查验和库存扣减这两个操作需要保证原子性。</p>
<p>第三阶段就是秒杀活动结束后。</p>
<p>在这个阶段，可能还会有部分用户刷新商品详情页，尝试等待有其他用户退单。而已经成功下单的用户会刷新订单详情，跟踪订单的进展。不过，这个阶段中的用户请求量已经下降很多了，服务器端一般都能支撑，我们就不重点讨论了。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/12321605-f043aa8017b0aecf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h4 id="数据量倾斜的成因？"><a href="#数据量倾斜的成因？" class="headerlink" title="数据量倾斜的成因？"></a>数据量倾斜的成因？</h4><h5 id="bigkey-导致倾斜"><a href="#bigkey-导致倾斜" class="headerlink" title="bigkey 导致倾斜"></a>bigkey 导致倾斜</h5><p>第一个原因是，某个实例上正好保存了 bigkey。bigkey 的 value 值很大（String 类型），或者是 bigkey 保存了大量集合元素（集合类型），会导致这个实例的数据量增加，内存资源消耗也相应增加。</p>
<p>其实，bigkey 已经是我们课程中反复提到的一个关键点了。为了避免 bigkey 造成的数据倾斜，一个根本的应对方法是，我们在业务层生成数据时，要尽量避免把过多的数据保存在同一个键值对中。</p>
<h5 id="Slot-分配不均衡导致倾斜"><a href="#Slot-分配不均衡导致倾斜" class="headerlink" title="Slot 分配不均衡导致倾斜"></a>Slot 分配不均衡导致倾斜</h5><p>如果集群运维人员没有均衡地分配 Slot，就会有大量的数据被分配到同一个 Slot 中，而同一个 Slot 只会在一个实例上分布，这就会导致，大量数据被集中到一个实例上，造成数据倾斜。</p>
<h5 id="Hash-Tag-导致倾斜"><a href="#Hash-Tag-导致倾斜" class="headerlink" title="Hash Tag 导致倾斜"></a>Hash Tag 导致倾斜</h5><p>Hash Tag 是指加在键值对 key 中的一对花括号{}。这对括号会把 key 的一部分括起来，客户端在计算 key 的 CRC16 值时，只对 Hash Tag 花括号中的 key 内容进行计算。如果没用 Hash Tag 的话，客户端计算整个 key 的 CRC16 的值。</p>
<p>我的建议是，如果使用 Hash Tag 进行切片的数据会带来较大的访问压力，就优先考虑避免数据倾斜，最好不要使用 Hash Tag 进行数据切片。因为事务和范围查询都还可以放在客户端来执行，而数据倾斜会导致实例不稳定，造成服务不可用。</p>
<h4 id="数据访问倾斜的成因和应对方法？"><a href="#数据访问倾斜的成因和应对方法？" class="headerlink" title="数据访问倾斜的成因和应对方法？"></a>数据访问倾斜的成因和应对方法？</h4><p>通常来说，热点数据以服务读操作为主，在这种情况下，我们可以采用热点数据多副本的方法来应对。</p>
<p>这个方法的具体做法是，我们把热点数据复制多份，在每一个数据副本的 key 中增加一个随机前缀，让它和其它副本数据不会被映射到同一个 Slot 中。这样一来，热点数据既有多个副本可以同时服务请求，同时，这些副本数据的 key 又不一样，会被映射到不同的 Slot 中。在给这些 Slot 分配实例时，我们也要注意把它们分配到不同的实例上，那么，热点数据的访问压力就被分散到不同的实例上了。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/12321605-d0bd20cb0f8ef019.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h2 id="Redis-Cluster-瓶颈"><a href="#Redis-Cluster-瓶颈" class="headerlink" title="Redis Cluster 瓶颈"></a>Redis Cluster 瓶颈</h2><p>Redis Cluster 能保存的数据量以及支撑的吞吐量，跟集群的实例规模密切相关。Redis 官方给出了 Redis Cluster 的规模上限，就是一个集群运行 1000 个实例。</p>
<p>那么，你可能会问，为什么要限定集群规模呢？其实，这里的一个关键因素就是，实例间的通信开销会随着实例规模增加而增大，在集群超过一定规模时（比如 800 节点），集群吞吐量反而会下降。所以，集群的实际规模会受到限制。</p>
<p>经过刚刚的分析，我们可以很直观地看到，实例间使用 Gossip 协议进行通信时，通信开销受到通信消息大小和通信频率这两方面的影响，</p>
<p>消息越大、频率越高，相应的通信开销也就越大。如果想要实现高效的通信，可以从这两方面入手去调优。接下来，我们就来具体分析下这两方面的实际情况。</p>
<h3 id="实例间通信频率"><a href="#实例间通信频率" class="headerlink" title="实例间通信频率"></a>实例间通信频率</h3><p>Redis Cluster 的实例启动后，默认会每秒从本地的实例列表中随机选出 5 个实例，再从这 5 个实例中找出一个最久没有通信的实例，把 PING 消息发送给该实例。这是实例周期性发送 PING 消息的基本做法。</p>
<p>但是，这里有一个问题：实例选出来的这个最久没有通信的实例，毕竟是从随机选出的 5 个实例中挑选的，这并不能保证这个实例就一定是整个集群中最久没有通信的实例。</p>
<p>所以，这有可能会出现，有些实例一直没有被发送 PING 消息，导致它们维护的集群状态已经过期了。</p>
<p>为了避免这种情况，Redis Cluster 的实例会按照每 100ms 一次的频率，扫描本地的实例列表，如果发现有实例最近一次接收 PONG 消息的时间，已经大于配置项 cluster-node-timeout 的一半了（cluster-node-timeout/2），就会立刻给该实例发送 PING 消息，更新这个实例上的集群状态信息。</p>
<h3 id="如何降低实例间的通信开销？"><a href="#如何降低实例间的通信开销？" class="headerlink" title="如何降低实例间的通信开销？"></a>如何降低实例间的通信开销？</h3><p>经过刚才的学习，我们现在知道，实例间发送消息的频率有两个。</p>
<ul>
<li>每个实例每 1 秒发送一条 PING 消息。这个频率不算高，如果再降低该频率的话，集群中各实例的状态可能就没办法及时传播了。</li>
<li>每个实例每 100 毫秒会做一次检测，给 PONG 消息接收超过 cluster-node-timeout/2 的节点发送 PING 消息。实例按照每 100 毫秒进行检测的频率，是 Redis 实例默认的周期性检查任务的统一频率，我们一般不需要修改它。</li>
</ul>
<p>那么，就只有 cluster-node-timeout 这个配置项可以修改了。</p>
<p>配置项 cluster-node-timeout 定义了集群实例被判断为故障的心跳超时时间，默认是 15 秒。如果 cluster-node-timeout 值比较小，那么，在大规模集群中，就会比较频繁地出现 PONG 消息接收超时的情况，从而导致实例每秒要执行 10 次“给 PONG 消息超时的实例发送 PING 消息”这个操作。</p>
<p>所以，为了避免过多的心跳消息挤占集群带宽，我们可以调大 cluster-node-timeout 值，比如说调大到 20 秒或 25 秒。这样一来， PONG 消息接收超时的情况就会有所缓解，单实例也不用频繁地每秒执行 10 次心跳发送操作了。</p>
<h2 id="Redis-6-0新特性"><a href="#Redis-6-0新特性" class="headerlink" title="Redis 6.0新特性"></a>Redis 6.0新特性</h2><p><img src="https://upload-images.jianshu.io/upload_images/12321605-eff6d48dba43409c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h3 id="从单线程处理网络请求到多线程处理"><a href="#从单线程处理网络请求到多线程处理" class="headerlink" title="从单线程处理网络请求到多线程处理"></a>从单线程处理网络请求到多线程处理</h3><p>在 Redis 6.0 中，非常受关注的第一个新特性就是多线程。这是因为，Redis 一直被大家熟知的就是它的单线程架构，虽然有些命令操作可以用后台线程或子进程执行（比如数据删除、快照生成、AOF 重写），但是，从网络 IO 处理到实际的读写命令处理，都是由单个线程完成的。</p>
<p>随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 IO 的处理上，也就是说，单个主线程处理网络请求的速度跟不上底层网络硬件的速度。</p>
<p>为了应对这个问题，一般有两种方法。</p>
<p>第一种方法是，用用户态网络协议栈（例如 DPDK）取代内核网络协议栈，让网络请求的处理不用在内核里执行，直接在用户态完成处理就行。</p>
<p>对于高性能的 Redis 来说，避免频繁让内核进行网络请求处理，可以很好地提升请求处理效率。但是，这个方法要求在 Redis 的整体架构中，添加对用户态网络协议栈的支持，需要修改 Redis 源码中和网络相关的部分（例如修改所有的网络收发请求函数），这会带来很多开发工作量。而且新增代码还可能引入新 Bug，导致系统不稳定。所以，Redis 6.0 中并没有采用这个方法。</p>
<p>第二种方法就是采用多个 IO 线程来处理网络请求，提高网络请求处理的并行度。Redis 6.0 就是采用的这种方法。</p>
<p>但是，Redis 的多 IO 线程只是用来处理网络请求的，对于读写命令，Redis 仍然使用单线程来处理。这是因为，Redis 处理请求时，网络处理经常是瓶颈，通过多个 IO 线程并行处理网络操作，可以提升实例的整体处理性能。而继续使用单线程执行命令操作，就不用为了保证 Lua 脚本、事务的原子性，额外开发多线程互斥机制了。这样一来，Redis 线程模型实现就简单了。</p>
<p>我们来看下，在 Redis 6.0 中，主线程和 IO 线程具体是怎么协作完成请求处理的。掌握了具体原理，你才能真正地会用多线程。为了方便你理解，我们可以把主线程和多 IO 线程的协作分成四个阶段。</p>
<p>阶段一：服务端和客户端建立 Socket 连接，并分配处理线程</p>
<p>首先，主线程负责接收建立连接请求。当有客户端请求和实例建立 Socket 连接时，主线程会创建和客户端的连接，并把 Socket 放入全局等待队列中。紧接着，主线程通过轮询方法把 Socket 连接分配给 IO 线程。</p>
<p>阶段二：IO 线程读取并解析请求</p>
<p>主线程一旦把 Socket 分配给 IO 线程，就会进入阻塞状态，等待 IO 线程完成客户端请求读取和解析。因为有多个 IO 线程在并行处理，所以，这个过程很快就可以完成。</p>
<p>阶段三：主线程执行请求操作</p>
<p>等到 IO 线程解析完请求，主线程还是会以单线程的方式执行这些命令操作。下面这张图显示了刚才介绍的这三个阶段，你可以看下，加深理解。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/12321605-810edf49237a7d3c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>阶段四：IO 线程回写 Socket 和主线程清空全局队列</p>
<p>当主线程执行完请求操作后，会把需要返回的结果写入缓冲区，然后，主线程会阻塞等待 IO 线程把这些结果回写到 Socket 中，并返回给客户端。</p>
<p>和 IO 线程读取和解析请求一样，IO 线程回写 Socket 时，也是有多个线程在并发执行，所以回写 Socket 的速度也很快。等到 IO 线程回写 Socket 完毕，主线程会清空全局队列，等待客户端的后续请求。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/12321605-f1e96f4d91df1f10.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<h2 id="Redis-和-Memcached、RocksDB-的对比"><a href="#Redis-和-Memcached、RocksDB-的对比" class="headerlink" title="Redis 和 Memcached、RocksDB 的对比"></a>Redis 和 Memcached、RocksDB 的对比</h2><p><img src="https://upload-images.jianshu.io/upload_images/12321605-3d57108cc0c9febe.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/12321605-91800a3647cd885c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/12321605-c3d1b71666f89fd8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
</article><section class="jump-container is-flex is-justify-content-space-between my-6"><!-- em is empty placeholder--><a class="button is-default" href="/2021/02/11/mysql-insert-lock/" title="MySQL Insert 死锁问题研究"><i class="iconfont icon-prev mr-2 has-text-grey"></i><span class="has-text-weight-semibold">上一页: MySQL Insert 死锁问题研究</span></a><a class="button is-default" href="/2021/02/08/ddd/" title="DDD-领域驱动设计"><span class="has-text-weight-semibold">下一页: DDD-领域驱动设计</span><i class="iconfont icon-next ml-2 has-text-grey"></i></a></section><article class="mt-6 comment-container"><script async repo="fanlv/blog" src="https://utteranc.es/client.js" issue-term="pathname" theme="preferred-color-scheme"></script></article></div></div></main></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/fanlv"><i class="iconfont icon-github"></i></a><!-- Ins--><a title="instagram" target="_blank" rel="noopener nofollow" href="//www.instagram.com/fanlvlgh"><i class="iconfont icon-ins"></i></a><!-- RSS--><!-- 知乎--><!-- 领英--><!-- 脸书--></section><p><span>Copyright ©</span><span> Ryo 2022</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"></div><div><span>博学之，审问之，慎思之，明辨之，笃行之</span></div></footer><script async defer src="https://buttons.github.io/buttons.js"></script><script src="/js/post.js"></script></body></html>